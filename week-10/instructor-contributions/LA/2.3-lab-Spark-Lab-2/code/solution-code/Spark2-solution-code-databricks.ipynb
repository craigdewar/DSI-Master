{"cells":[{"cell_type":"markdown","source":["# Spark Lab 2: MLLib\n\nIn this lab we will explore the MLLib library for machine learning in Spark. The API of this library is very similar to Scikit Learn, and it plays quite nicely with Pandas.\n\nThis lab follows quite closely [this blog post](https://www.mapr.com/blog/churn-prediction-pyspark-using-mllib-and-ml-packages), so if you're lost you can go have look there for guidance.\n\nThere are two ways to run this pySpark notebook: \n(1) Databricks community version\n(2) GA Bigdata VM\n\nYou can choose to start start with the usual:\n    - vagrant up\n    - vagrant ssh\n    - bigdata_start.sh \n    \nNow you should have access to Jupyter notebook here:\n\n    http://10.211.55.101:18888/tree\n    \nThe problem we will solve is the prediction of [_churn rate_](https://en.wikipedia.org/wiki/Churn_rate), which is a measure of how many customers are lost over a period of time. This is a very important business metric, in particular for large companies like Telecom companies.\n\nWe will use a dataset provided by [BigML](https://bigml.com/). The data has been copied to your VM, but can also be downloaded [here](https://bml-data.s3.amazonaws.com/churn-bigml-80.csv) and [here](https://bml-data.s3.amazonaws.com/churn-bigml-20.csv)."],"metadata":{}},{"cell_type":"code","source":["# Disable warnings, set Matplotlib inline plotting and load Pandas package\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\n%matplotlib inline\n#pd.options.display.mpl_style = 'default'"],"metadata":{"collapsed":false},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["Check that the SparkContext and sqlContext are available"],"metadata":{}},{"cell_type":"code","source":["sc"],"metadata":{"collapsed":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":["print sqlContext\n\n#get help from spark\nprint dir(sqlContext)\nprint help(sqlContext)"],"metadata":{"collapsed":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["## Exercise 1.a: Load the data\n\nLet's start by loading the data. Since the input is a CSV file we'll need to provide a parser.\n\n- Use the sqlContext.read.load function to load the data\n    - load the bigml-80 file to an RDD called CV_data\n    - load the bigml-20 file to an RDD called final_test_data\n    - cache CV_data to speed up things\n    \nNote that you can print the schema of the RDD if you want to"],"metadata":{}},{"cell_type":"code","source":["#mount your s3 bucket - only need to do this once\n#delete the below code after it has been mounted \n# insert code here with AWS\n#############\n#############\n#############"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(dbutils.fs.ls(\"/mnt/my_data\"))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# get_data_from_s3 = sc.textFile(\"dbfs:/mnt/my-data/churn-bigml-20.csv\")\n# get_data_from_s3.count()\n\nfinal_test_data = sc.textFile(\"s3a://%s:%s@%s/churn-bigml-20.csv\" % (ACCESS_KEY, SECRET_KEY, AWS_BUCKET_NAME))\nCV_data = sc.textFile(\"s3a://%s:%s@%s/churn-bigml-80.csv\" % (ACCESS_KEY, SECRET_KEY, AWS_BUCKET_NAME))\n\n\nprint 'CV_data count: ', CV_data.count()\nprint 'final_test_data count: ', final_test_data.count()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#select by table method\n#CV_data = sqlContext.sql(\"select * from churn_bigml_20 LIMIT 100\") #_80 table had trouble loading in databricks\n#final_test_data = sqlContext.sql(\"select * from churn_bigml_80 LIMIT 100\") \n\n#select by GA big data VM\n# CV_data = sqlContext.read.load('file:///home/vagrant/data/churn/churn-bigml-80.csv', \n#                           format='com.databricks.spark.csv', \n#                           header='true', \n#                           inferSchema='true')\n\n# final_test_data = sqlContext.read.load('file:///home/vagrant/data/churn/churn-bigml-20.csv', \n#                           format='com.databricks.spark.csv', \n#                           header='true', \n#                           inferSchema='true')\nCV_data.cache()\nCV_data.printSchema()\n"],"metadata":{"collapsed":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["## Exercise 1.b: Quick look at the data\n\n- use the `take` function to take the first 5 lines of the `CV_data` RDD and display them as Pandas dataframe\n- use the `describe` function to have some summary statistics about the training data"],"metadata":{}},{"cell_type":"code","source":["pd.DataFrame(CV_data.take(5), columns=CV_data.columns).transpose()\n"],"metadata":{"collapsed":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":["CV_data.describe().toPandas().transpose()"],"metadata":{"collapsed":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["## Exercise 2: Sample inspection\n\nNot all the features are numeric. `CV_data.dtypes` contains information on the type.\n\n- select the features that are either `int` or `double`\n- use the `sample` function to get a 10% sample of the training RDD\n- Display a Pandas.scatter_matrix of the sampled data"],"metadata":{}},{"cell_type":"code","source":["#code works in GA bigdata VM and in data bricks\n#%matplotlib inline \n\nnumeric_features = [t[0] for t in CV_data.dtypes if t[1] == 'int' or t[1] == 'double']\n\nsampled_data = CV_data.select(numeric_features).sample(False, 0.10).toPandas()\n\naxs = pd.scatter_matrix(sampled_data, figsize=(12, 12));\n\n# Rotate axis labels and remove axis ticks\nn = len(sampled_data.columns)\nfor i in range(n):\n    v = axs[i, 0]\n    v.yaxis.label.set_rotation(0)\n    v.yaxis.label.set_ha('right')\n    v.set_yticks(())\n    h = axs[n-1, i]\n    h.xaxis.label.set_rotation(90)\n    h.set_xticks(())\n\n#axs.show()"],"metadata":{"collapsed":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#special feature in data bricks\ndisplay(CV_data)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["## Exercise 3: Feature selection\n\nColumn selection on an RDD works differently than in Scikit Learn. For example if we want to drop 2 columns in Spark, we just apply the `.drop(column)` function 2 times.\n\n- Drop the following columns:\n    - State\n    - Area Code\n    - Total day charge\n    - Total eve charge\n    - Total night charge\n    - Total intl charge\n    \nAlso, we can apply a function to a column with the construct:\n\n    .withColumn('column_name', function(CV_data['column_name']))\n    \nUse it to transform binary string labels to `1.0` or `0.0`. Treat these columns:\n\n    - Churn\n    - International plan\n    - Voice mail plan\n\nYou may need these two imports:\n\n```python\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.sql.functions import UserDefinedFunction\n```\n\nAlso, use the `.cache` function to cache your pipeline results so far."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import DoubleType\nfrom pyspark.sql.functions import UserDefinedFunction\n\nbinary_map = {'Yes':1.0, 'No':0.0, 'True':1.0, 'False':0.0}\ntoNum = UserDefinedFunction(lambda k: binary_map[k], DoubleType())\n\nCV_data = CV_data.drop('State').drop('Area code') \\\n    .drop('Total day charge').drop('Total eve charge') \\\n    .drop('Total night charge').drop('Total intl charge') \\\n    .withColumn('Churn', toNum(CV_data['Churn'])) \\\n    .withColumn('International plan', toNum(CV_data['International plan'])) \\\n    .withColumn('Voice mail plan', toNum(CV_data['Voice mail plan'])).cache()\n\nfinal_test_data = final_test_data.drop('State').drop('Area code') \\\n    .drop('Total day charge').drop('Total eve charge') \\\n    .drop('Total night charge').drop('Total intl charge') \\\n    .withColumn('Churn', toNum(final_test_data['Churn'])) \\\n    .withColumn('International plan', toNum(final_test_data['International plan'])) \\\n    .withColumn('Voice mail plan', toNum(final_test_data['Voice mail plan'])).cache()"],"metadata":{"collapsed":true},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["As before, take 5 lines and display them with Pandas"],"metadata":{}},{"cell_type":"code","source":["pd.DataFrame(CV_data.take(5), columns=CV_data.columns).transpose()"],"metadata":{"collapsed":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["## Exercise 4: Train Decision Tree\n\nTime has come to do our first model using MLLib. We will use a decision tree.\n\n- [LabeledPoint](https://spark.apache.org/docs/0.8.1/api/mllib/org/apache/spark/mllib/regression/LabeledPoint.html) allows us to represent a data point with features and labels. Map it across the data using a function\n- `.randomSplit` allows us to split the data in train/test sets. Do an 80/20 split\n- Train a [DecisionTree](http://spark.apache.org/docs/latest/mllib-decision-tree.html) on the training data\n- Display the trained model using `print model.toDebugString()`\n\nYou may need the following imports:\n\n```python\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.tree import DecisionTree\n```"],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.tree import DecisionTree\n\ndef labelData(data):\n    # label: row[end], features: row[0:end-1]\n    return data.map(lambda row: LabeledPoint(row[-1], row[:-1]))\n\ntraining_data, testing_data = labelData(CV_data).randomSplit([0.8, 0.2])\n\nmodel = DecisionTree.trainClassifier(training_data, numClasses=2, maxDepth=2,\n                                     categoricalFeaturesInfo={1:2, 2:2},\n                                     impurity='gini', maxBins=32)\n\nprint model.toDebugString()"],"metadata":{"collapsed":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":["print 'Feature 12:', CV_data.columns[12]\nprint 'Feature 4: ', CV_data.columns[4]"],"metadata":{"collapsed":true},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["## Exercise 5: Model valuation\n\n\nThe MulticlassMetrics module contains a lot of metrics functions.\n\n- Evaluate the model on the test data using `.predict`\n- Calculate the following metrics:\n    - Precision of True \n    - Precision of False\n    - Recall of True    \n    - Recall of False   \n    - F-1 Score         \n    - Confusion Matrix\n\n- Finally, display how many \n\n```python\nfrom pyspark.mllib.evaluation import MulticlassMetrics\n```"],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.evaluation import MulticlassMetrics\n\ndef getPredictionsLabels(model, test_data):\n    predictions = model.predict(test_data.map(lambda r: r.features))\n    return predictions.zip(test_data.map(lambda r: r.label))\n\ndef printMetrics(predictions_and_labels):\n    metrics = MulticlassMetrics(predictions_and_labels)\n    print 'Precision of True ', metrics.precision(1)\n    print 'Precision of False', metrics.precision(0)\n    print 'Recall of True    ', metrics.recall(1)\n    print 'Recall of False   ', metrics.recall(0)\n    print 'F-1 Score         ', metrics.fMeasure()\n    print 'Confusion Matrix\\n', metrics.confusionMatrix().toArray()\n\npredictions_and_labels = getPredictionsLabels(model, testing_data)\n\nprintMetrics(predictions_and_labels)"],"metadata":{"collapsed":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":["CV_data.groupby('Churn').count().toPandas()"],"metadata":{"collapsed":true},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["## Bonus: Cross Validation\n\nThe [original blog post mentioned above](https://www.mapr.com/blog/churn-prediction-pyspark-using-mllib-and-ml-packages) also contains code to implement cross validation. Try it and see if you understand how it's done."],"metadata":{}},{"cell_type":"code","source":["stratified_CV_data = CV_data.sampleBy('Churn', fractions={0: 388./2278, 1: 1.0}).cache()\n\nstratified_CV_data.groupby('Churn').count().toPandas()"],"metadata":{"collapsed":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":["training_data, testing_data = labelData(stratified_CV_data).randomSplit([0.8, 0.2])\n\nmodel = DecisionTree.trainClassifier(training_data, numClasses=2, maxDepth=2,\n                                     categoricalFeaturesInfo={1:2, 2:2},\n                                     impurity='gini', maxBins=32)\n\npredictions_and_labels = getPredictionsLabels(model, testing_data)\nprintMetrics(predictions_and_labels)"],"metadata":{"collapsed":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":["from pyspark.mllib.linalg import Vectors\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorIndexer\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\ndef vectorizeData(data):\n    return data.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).toDF(['label','features'])\n\nvectorized_CV_data = vectorizeData(stratified_CV_data)\n\n# Index labels, adding metadata to the label column\nlabelIndexer = StringIndexer(inputCol='label',\n                             outputCol='indexedLabel').fit(vectorized_CV_data)\n\n# Automatically identify categorical features and index them\nfeatureIndexer = VectorIndexer(inputCol='features',\n                               outputCol='indexedFeatures',\n                               maxCategories=2).fit(vectorized_CV_data)\n\n# Train a DecisionTree model\ndTree = DecisionTreeClassifier(labelCol='indexedLabel', featuresCol='indexedFeatures')\n\n# Chain indexers and tree in a Pipeline\npipeline = Pipeline(stages=[labelIndexer, featureIndexer, dTree])\n\n# Search through decision tree's maxDepth parameter for best model\nparamGrid = ParamGridBuilder().addGrid(dTree.maxDepth, [2,3,4,5,6,7]).build()\n\n# Set F-1 score as evaluation metric for best model selection\nevaluator = MulticlassClassificationEvaluator(labelCol='indexedLabel',\n                                              predictionCol='prediction', metricName='f1')    \n\n# Set up 3-fold cross validation\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=3)\n\nCV_model = crossval.fit(vectorized_CV_data)\n\n# Fetch best model\ntree_model = CV_model.bestModel.stages[2]\nprint tree_model"],"metadata":{"collapsed":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":["vectorized_test_data = vectorizeData(final_test_data)\n\ntransformed_data = CV_model.transform(vectorized_test_data)\nprint evaluator.getMetricName(), 'accuracy:', evaluator.evaluate(transformed_data)\n\npredictions = transformed_data.select('indexedLabel', 'prediction', 'probability')\npredictions.toPandas().head()"],"metadata":{"collapsed":true},"outputs":[],"execution_count":31},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":32}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2.0},"version":"2.7.11","nbconvert_exporter":"python","file_extension":".py"},"name":"Spark2-solution-code","notebookId":4219986722115091},"nbformat":4,"nbformat_minor":0}
