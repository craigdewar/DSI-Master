{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets as datasets\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house = datasets.load_boston()\n",
    "bcancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Housing data target variable is price: continuous!\n",
    "# If Y is continuous, use regression. Regression predicts mean Y (E[Y] given X)\n",
    "# alternatively Y ~ B*X\n",
    "Xh, Yh = pd.DataFrame(house.data, columns=house.feature_names), house.target\n",
    "\n",
    "# Breast cancer target is categorical; has breast cancer or not.\n",
    "# If Y is categorical, use classification. \n",
    "# Classification predicts probability of category (E[P(Y == 1)])\n",
    "# alternatively (for logistic regression only though): Y ~ BX\n",
    "Xb, Yb = pd.DataFrame(bcancer.data, columns=bcancer.feature_names), bcancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'CRIM', u'ZN', u'INDUS', u'CHAS', u'NOX', u'RM', u'AGE', u'DIS',\n",
      "       u'RAD', u'TAX', u'PTRATIO', u'B', u'LSTAT'],\n",
      "      dtype='object')\n",
      "Index([u'mean radius', u'mean texture', u'mean perimeter', u'mean area',\n",
      "       u'mean smoothness', u'mean compactness', u'mean concavity',\n",
      "       u'mean concave points', u'mean symmetry', u'mean fractal dimension',\n",
      "       u'radius error', u'texture error', u'perimeter error', u'area error',\n",
      "       u'smoothness error', u'compactness error', u'concavity error',\n",
      "       u'concave points error', u'symmetry error', u'fractal dimension error',\n",
      "       u'worst radius', u'worst texture', u'worst perimeter', u'worst area',\n",
      "       u'worst smoothness', u'worst compactness', u'worst concavity',\n",
      "       u'worst concave points', u'worst symmetry', u'worst fractal dimension'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print Xh.columns\n",
    "print Xb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24. ,  21.6,  34.7,  33.4,  36.2,  28.7,  22.9,  27.1,  16.5,  18.9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yh[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS       float64\n",
       "NOX        float64\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD        float64\n",
       "TAX        float64\n",
       "PTRATIO    float64\n",
       "B          float64\n",
       "LSTAT      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check predictor types in case there are categorical in there...\n",
    "Xh.dtypes\n",
    "\n",
    "# IF  YOU HAVE LOTS OF CATEGORICAL, USING PATSY IS WAY LESS WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First construct the linear regression using the \"blueprint\"\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Fit the linear regression on your target and predictors:\n",
    "# x is pandas dataframe, so convert to matrix! keep track of column names\n",
    "Xh_columns = Xh.columns\n",
    "Xh_mat = Xh.values\n",
    "\n",
    "house_linreg = linear_reg.fit(Xh_mat, Yh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24.   21.6  34.7  33.4  36.2  28.7  22.9  27.1  16.5  18.9]\n",
      "[ 30.00821269  25.0298606   30.5702317   28.60814055  27.94288232\n",
      "  25.25940048  23.00433994  19.5347558   11.51696539  18.91981483]\n"
     ]
    }
   ],
   "source": [
    "# PREDICTIONS!\n",
    "Yh_predictions = house_linreg.predict(Xh_mat)\n",
    "\n",
    "print Yh[0:10]\n",
    "print Yh_predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74060774286494269"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is our model good? Let's check the R2 for the model.\n",
    "# Since we are just using our original data to predict, put it in the score function.\n",
    "house_linreg.score(Xh_mat, Yh)\n",
    "\n",
    "# WTF is R2?\n",
    "# this is the proportion of variance explained in our target variable \n",
    "# COMPARED TO A MODEL THAT JUST USES MEAN OF Y (baseline model)\n",
    "# aka: how much better is the model compared to just guessing every Y row with the mean\n",
    "# of Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.07170557e-01   4.63952195e-02   2.08602395e-02   2.68856140e+00\n",
      "  -1.77957587e+01   3.80475246e+00   7.51061703e-04  -1.47575880e+00\n",
      "   3.05655038e-01  -1.23293463e-02  -9.53463555e-01   9.39251272e-03\n",
      "  -5.25466633e-01]\n"
     ]
    }
   ],
   "source": [
    "# what are our coefficients from the model?\n",
    "print house_linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.107171</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046395</td>\n",
       "      <td>ZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020860</td>\n",
       "      <td>INDUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.688561</td>\n",
       "      <td>CHAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.795759</td>\n",
       "      <td>NOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.804752</td>\n",
       "      <td>RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000751</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.475759</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.305655</td>\n",
       "      <td>RAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.012329</td>\n",
       "      <td>TAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.953464</td>\n",
       "      <td>PTRATIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.009393</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.525467</td>\n",
       "      <td>LSTAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coef  feature\n",
       "0   -0.107171     CRIM\n",
       "1    0.046395       ZN\n",
       "2    0.020860    INDUS\n",
       "3    2.688561     CHAS\n",
       "4  -17.795759      NOX\n",
       "5    3.804752       RM\n",
       "6    0.000751      AGE\n",
       "7   -1.475759      DIS\n",
       "8    0.305655      RAD\n",
       "9   -0.012329      TAX\n",
       "10  -0.953464  PTRATIO\n",
       "11   0.009393        B\n",
       "12  -0.525467    LSTAT"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at this in a nicer way. we saved the column values earlier, conveniently\n",
    "house_coefs = pd.DataFrame({'feature':Xh_columns, 'coef':house_linreg.coef_})\n",
    "\n",
    "# Remember that for linear regression the formula is Y ~ b1*x1 + ... + bn*xn\n",
    "# for our x1 thru xn columns of predictors.\n",
    "# To estimate Y for a row of predictor variables, we multiply each of these\n",
    "# coefficients by their respective beta coefficients and add them together!\n",
    "house_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO\n",
    "\n",
    "Why would we use the Lasso?\n",
    "\n",
    "Lasso, depending on the **regularization strength alpha**, will eliminate variables in order of their value or importance on predicting Y.\n",
    "\n",
    "In this case we probably don't need it for the data (will likely make prediction worse if we remove variables), but this is just a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize Lasso just as you would the linear regression...\n",
    "\n",
    "# Let's make 2. One with \"weak\" regularization, which means there is a\n",
    "# very small penalty on coefficient sizes.\n",
    "# Coefficients added up can be big and it won't really care (basically\n",
    "# will be the same as vanilla Linear Regression)\n",
    "house_lasso_weak = Lasso(alpha=0.01)\n",
    "\n",
    "# make one that has strong regularization\n",
    "house_lasso_strong = Lasso(alpha=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit them each on data\n",
    "h_weak = house_lasso_weak.fit(Xh_mat, Yh)\n",
    "h_strong = house_lasso_strong.fit(Xh_mat, Yh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make tables of coefficients to see what lassos did\n",
    "weak_coefs = pd.DataFrame({'feature':Xh_columns, 'coef':h_weak.coef_})\n",
    "strong_coefs = pd.DataFrame({'feature':Xh_columns, 'coef':h_strong.coef_})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.105331</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046833</td>\n",
       "      <td>ZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006776</td>\n",
       "      <td>INDUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.506079</td>\n",
       "      <td>CHAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.422629</td>\n",
       "      <td>NOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.809185</td>\n",
       "      <td>RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.001761</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.422294</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.298100</td>\n",
       "      <td>RAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.012622</td>\n",
       "      <td>TAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.917067</td>\n",
       "      <td>PTRATIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.009566</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.531194</td>\n",
       "      <td>LSTAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coef  feature\n",
       "0   -0.105331     CRIM\n",
       "1    0.046833       ZN\n",
       "2    0.006776    INDUS\n",
       "3    2.506079     CHAS\n",
       "4  -14.422629      NOX\n",
       "5    3.809185       RM\n",
       "6   -0.001761      AGE\n",
       "7   -1.422294      DIS\n",
       "8    0.298100      RAD\n",
       "9   -0.012622      TAX\n",
       "10  -0.917067  PTRATIO\n",
       "11   0.009566        B\n",
       "12  -0.531194    LSTAT"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does weak look like?\n",
    "weak_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>ZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>INDUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>CHAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>NOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>RAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.020972</td>\n",
       "      <td>TAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>PTRATIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.004466</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>LSTAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef  feature\n",
       "0  -0.000000     CRIM\n",
       "1   0.000000       ZN\n",
       "2  -0.000000    INDUS\n",
       "3   0.000000     CHAS\n",
       "4  -0.000000      NOX\n",
       "5   0.000000       RM\n",
       "6  -0.000000      AGE\n",
       "7   0.000000      DIS\n",
       "8  -0.000000      RAD\n",
       "9  -0.020972      TAX\n",
       "10 -0.000000  PTRATIO\n",
       "11  0.004466        B\n",
       "12 -0.000000    LSTAT"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22497922550751603"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When fit on its own data, it will be worse than LinearRegression\n",
    "# but when using crossvalidation it will sometimes perform better.\n",
    "house_lasso_strong.score(Xh_mat, Yh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIDGE REGRESSION\n",
    "\n",
    "Ridge penalty has a different effect on our coefficients. Without getting into the math (you can review the slides in the lesson), it \"shrinks\" all our coefficients down.\n",
    "\n",
    "This is particularly useful if a lot of our predictor variables are correlated with each other.\n",
    "\n",
    "Why?\n",
    "\n",
    "Basically, because the coefficients shrink for the correlated variables, they can contribute more equally to the prediction. The reason that can be good is that **in our sample of data, one may be a better predictor than the other, but in a new sample, the other one might be better!**\n",
    "\n",
    "You are hedging your bets on the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Again, set up two ridges, one with strong regularization, one with weak.\n",
    "# Weak will be similar if not the same to the LinearRegression\n",
    "# Strong will make the beta values very small, but more equal to each other in magnitude.\n",
    "h_ridge_weak = Ridge(alpha=0.01)\n",
    "h_ridge_strong = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit models\n",
    "ridge_weak_mod = h_ridge_weak.fit(Xh_mat, Yh)\n",
    "ridge_strong_mod = h_ridge_strong.fit(Xh_mat, Yh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_weak_coefs = pd.DataFrame({'feature':Xh_columns, 'coef':ridge_weak_mod.coef_})\n",
    "ridge_strong_coefs = pd.DataFrame({'feature':Xh_columns, 'coef':ridge_strong_mod.coef_})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.107111</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046411</td>\n",
       "      <td>ZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020377</td>\n",
       "      <td>INDUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.686838</td>\n",
       "      <td>CHAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.681068</td>\n",
       "      <td>NOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.805660</td>\n",
       "      <td>RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000649</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.474067</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.305385</td>\n",
       "      <td>RAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.012338</td>\n",
       "      <td>TAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.952191</td>\n",
       "      <td>PTRATIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.009398</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.525593</td>\n",
       "      <td>LSTAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coef  feature\n",
       "0   -0.107111     CRIM\n",
       "1    0.046411       ZN\n",
       "2    0.020377    INDUS\n",
       "3    2.686838     CHAS\n",
       "4  -17.681068      NOX\n",
       "5    3.805660       RM\n",
       "6    0.000649      AGE\n",
       "7   -1.474067      DIS\n",
       "8    0.305385      RAD\n",
       "9   -0.012338      TAX\n",
       "10  -0.952191  PTRATIO\n",
       "11   0.009398        B\n",
       "12  -0.525593    LSTAT"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_weak_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.101451</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.054470</td>\n",
       "      <td>ZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.052626</td>\n",
       "      <td>INDUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.638647</td>\n",
       "      <td>CHAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.263245</td>\n",
       "      <td>NOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.331966</td>\n",
       "      <td>RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001230</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.153157</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.314915</td>\n",
       "      <td>RAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.015852</td>\n",
       "      <td>TAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.829503</td>\n",
       "      <td>PTRATIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.009471</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.661312</td>\n",
       "      <td>LSTAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef  feature\n",
       "0  -0.101451     CRIM\n",
       "1   0.054470       ZN\n",
       "2  -0.052626    INDUS\n",
       "3   0.638647     CHAS\n",
       "4  -0.263245      NOX\n",
       "5   2.331966       RM\n",
       "6   0.001230      AGE\n",
       "7  -1.153157      DIS\n",
       "8   0.314915      RAD\n",
       "9  -0.015852      TAX\n",
       "10 -0.829503  PTRATIO\n",
       "11  0.009471        B\n",
       "12 -0.661312    LSTAT"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_strong_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kNN classifies between categories (in the case of the breast cancer data, \n",
    "# it is going to classify observations (X rows) as either 1 or 0).\n",
    "\n",
    "# The way it does this is by checking out the \"neighbors\" of an observation.\n",
    "# The nearest neighbor of an observation is the one that has the most \n",
    "# similar values for each X predictor. It calculates (typically)\n",
    "# the euclidean distance.\n",
    "\n",
    "# You choose how many neighbors will \"take a vote\" on what the class\n",
    "# of the new observation should be. The voting can be equal\n",
    "# (weights='uniform') which means they all get an equal vote, or\n",
    "# the weighting can be adjusted for distance (weights='distance')\n",
    "# where the closer you are, the more important your vote is.\n",
    "\n",
    "knn_3neighbors = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_11neighbors = KNeighborsClassifier(n_neighbors=11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xb_mat = Xb.values\n",
    "Xb_cols = Xb.columns\n",
    "\n",
    "# fit the x, y data for the neighbors:\n",
    "knn3 = knn_3neighbors.fit(Xb_mat, Yb)\n",
    "knn11 = knn_11neighbors.fit(Xb_mat, Yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.627416520211\n",
      "knn3 acc: 0.956063268893\n",
      "knn11 acc: 0.940246045694\n"
     ]
    }
   ],
   "source": [
    "# score the models - the default score for classifiers is the accuracy\n",
    "# this is the proportion of observations that were assigned the correct\n",
    "# label.\n",
    "\n",
    "# First look at the \"base rate\" accuracy, which is the proportion of 1s \n",
    "# relative to zeros.\n",
    "print np.mean(Yb)\n",
    "\n",
    "print 'knn3 acc:', knn3.score(Xb_mat, Yb)\n",
    "print 'knn11 acc:', knn11.score(Xb_mat, Yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN bias-variance in a nutshell\n",
    "\n",
    "**Smaller number of neighbors = higher variance, lower bias**: \n",
    "\n",
    "**Higher number of neighbors = lower variance, higher bias:** in the extreme, if you use all the neighbors (all the points), you are just estimating the mean number of Y 1s relative to 0s (note: this is only in the case of uniform weights, but bias increases for distance too, just not to the mean.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with Ridge and Lasso\n",
    "\n",
    "We can use ridge and lasso in logistic regression just like with normal regression problems, but logistic regression is predicting probabilities not mean values!\n",
    "\n",
    "**NOTE: the regularization parameter is now C instead of alpha, which is basically 1/alpha (inverse of regularization strength).**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the standard, ridge, and lasso logistic regressions:\n",
    "lr_standard = LogisticRegression()\n",
    "# REMEMBER: the penalty string is lowercase \"L\" first, NOT 1\n",
    "lr_lasso = LogisticRegression(penalty='l1', solver='liblinear', C=0.1)\n",
    "lr_ridge = LogisticRegression(penalty='l2', C=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NORMALIZE THE PREDICTOR VARIABLES!\n",
    "# this makes the betas relative to each other, so you can directly compare the\n",
    "# effect of one variable on the log odds to another variable. Otherwise they\n",
    "# are very difficult to interpret\n",
    "Xb_mat = ((Xb - Xb.mean()) / Xb.std()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_std_mod = lr_standard.fit(Xb_mat, Yb)\n",
    "lr_l1_mod = lr_lasso.fit(Xb_mat, Yb)\n",
    "lr_l2_mod = lr_ridge.fit(Xb_mat, Yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get out the coefficients for each model so you can see the effect of ridge, lasso \n",
    "# on the logistic regression coefficients.\n",
    "#\n",
    "# logistic regression coefficients are a list of lists. This is because in the\n",
    "# multinomial (many class) case it will have the coefficients for each logistic\n",
    "# regression that was fit. In the binary case, there is just one list inside.\n",
    "def make_coef_df(Xb, mod):\n",
    "    df = pd.DataFrame({'features':Xb.columns, 'coefs':mod.coef_[0]})\n",
    "    return df\n",
    "\n",
    "lr_std_coefs = make_coef_df(Xb, lr_std_mod)\n",
    "lr_l1_coefs = make_coef_df(Xb, lr_l1_mod)\n",
    "lr_l2_coefs = make_coef_df(Xb, lr_l2_mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.354258</td>\n",
       "      <td>mean radius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.385699</td>\n",
       "      <td>mean texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.342896</td>\n",
       "      <td>mean perimeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.441885</td>\n",
       "      <td>mean area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.155334</td>\n",
       "      <td>mean smoothness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.567933</td>\n",
       "      <td>mean compactness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.868805</td>\n",
       "      <td>mean concavity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.968382</td>\n",
       "      <td>mean concave points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.073177</td>\n",
       "      <td>mean symmetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.311547</td>\n",
       "      <td>mean fractal dimension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.295574</td>\n",
       "      <td>radius error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.269882</td>\n",
       "      <td>texture error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.666759</td>\n",
       "      <td>perimeter error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.029707</td>\n",
       "      <td>area error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.281271</td>\n",
       "      <td>smoothness error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.742864</td>\n",
       "      <td>compactness error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.113414</td>\n",
       "      <td>concavity error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.320095</td>\n",
       "      <td>concave points error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.289980</td>\n",
       "      <td>symmetry error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.671606</td>\n",
       "      <td>fractal dimension error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.030838</td>\n",
       "      <td>worst radius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.313500</td>\n",
       "      <td>worst texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.826061</td>\n",
       "      <td>worst perimeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.029429</td>\n",
       "      <td>worst area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.672419</td>\n",
       "      <td>worst smoothness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.048786</td>\n",
       "      <td>worst compactness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.871977</td>\n",
       "      <td>worst concavity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.911816</td>\n",
       "      <td>worst concave points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.884370</td>\n",
       "      <td>worst symmetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.483495</td>\n",
       "      <td>worst fractal dimension</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coefs                 features\n",
       "0  -0.354258              mean radius\n",
       "1  -0.385699             mean texture\n",
       "2  -0.342896           mean perimeter\n",
       "3  -0.441885                mean area\n",
       "4  -0.155334          mean smoothness\n",
       "5   0.567933         mean compactness\n",
       "6  -0.868805           mean concavity\n",
       "7  -0.968382      mean concave points\n",
       "8   0.073177            mean symmetry\n",
       "9   0.311547   mean fractal dimension\n",
       "10 -1.295574             radius error\n",
       "11  0.269882            texture error\n",
       "12 -0.666759          perimeter error\n",
       "13 -1.029707               area error\n",
       "14 -0.281271         smoothness error\n",
       "15  0.742864        compactness error\n",
       "16  0.113414          concavity error\n",
       "17 -0.320095     concave points error\n",
       "18  0.289980           symmetry error\n",
       "19  0.671606  fractal dimension error\n",
       "20 -1.030838             worst radius\n",
       "21 -1.313500            worst texture\n",
       "22 -0.826061          worst perimeter\n",
       "23 -1.029429               worst area\n",
       "24 -0.672419         worst smoothness\n",
       "25  0.048786        worst compactness\n",
       "26 -0.871977          worst concavity\n",
       "27 -0.911816     worst concave points\n",
       "28 -0.884370           worst symmetry\n",
       "29 -0.483495  worst fractal dimension"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at standard logistic regression coefficients\n",
    "lr_std_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.087617</td>\n",
       "      <td>mean radius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.056655</td>\n",
       "      <td>mean texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.088180</td>\n",
       "      <td>mean perimeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.083912</td>\n",
       "      <td>mean area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.037799</td>\n",
       "      <td>mean smoothness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.058437</td>\n",
       "      <td>mean compactness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.074833</td>\n",
       "      <td>mean concavity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.089509</td>\n",
       "      <td>mean concave points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.033346</td>\n",
       "      <td>mean symmetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015474</td>\n",
       "      <td>mean fractal dimension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.064544</td>\n",
       "      <td>radius error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002643</td>\n",
       "      <td>texture error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.060748</td>\n",
       "      <td>perimeter error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.060947</td>\n",
       "      <td>area error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.009734</td>\n",
       "      <td>smoothness error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.016198</td>\n",
       "      <td>compactness error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.011631</td>\n",
       "      <td>concavity error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.035379</td>\n",
       "      <td>concave points error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.006637</td>\n",
       "      <td>symmetry error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.008663</td>\n",
       "      <td>fractal dimension error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.095166</td>\n",
       "      <td>worst radius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.064912</td>\n",
       "      <td>worst texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.094407</td>\n",
       "      <td>worst perimeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.088086</td>\n",
       "      <td>worst area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.054670</td>\n",
       "      <td>worst smoothness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.064365</td>\n",
       "      <td>worst compactness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.073476</td>\n",
       "      <td>worst concavity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.094022</td>\n",
       "      <td>worst concave points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.054171</td>\n",
       "      <td>worst symmetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.033179</td>\n",
       "      <td>worst fractal dimension</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coefs                 features\n",
       "0  -0.087617              mean radius\n",
       "1  -0.056655             mean texture\n",
       "2  -0.088180           mean perimeter\n",
       "3  -0.083912                mean area\n",
       "4  -0.037799          mean smoothness\n",
       "5  -0.058437         mean compactness\n",
       "6  -0.074833           mean concavity\n",
       "7  -0.089509      mean concave points\n",
       "8  -0.033346            mean symmetry\n",
       "9   0.015474   mean fractal dimension\n",
       "10 -0.064544             radius error\n",
       "11  0.002643            texture error\n",
       "12 -0.060748          perimeter error\n",
       "13 -0.060947               area error\n",
       "14  0.009734         smoothness error\n",
       "15 -0.016198        compactness error\n",
       "16 -0.011631          concavity error\n",
       "17 -0.035379     concave points error\n",
       "18  0.006637           symmetry error\n",
       "19  0.008663  fractal dimension error\n",
       "20 -0.095166             worst radius\n",
       "21 -0.064912            worst texture\n",
       "22 -0.094407          worst perimeter\n",
       "23 -0.088086               worst area\n",
       "24 -0.054670         worst smoothness\n",
       "25 -0.064365        worst compactness\n",
       "26 -0.073476          worst concavity\n",
       "27 -0.094022     worst concave points\n",
       "28 -0.054171           worst symmetry\n",
       "29 -0.033179  worst fractal dimension"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at ridge coefs:\n",
    "lr_l2_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>mean radius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>mean texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>mean perimeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>mean area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>mean smoothness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>mean compactness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>mean concavity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.629997</td>\n",
       "      <td>mean concave points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>mean symmetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>mean fractal dimension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.514483</td>\n",
       "      <td>radius error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>texture error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>perimeter error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>area error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>smoothness error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>compactness error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>concavity error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>concave points error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>symmetry error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>fractal dimension error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-2.348455</td>\n",
       "      <td>worst radius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.694616</td>\n",
       "      <td>worst texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>worst perimeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>worst area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.257861</td>\n",
       "      <td>worst smoothness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>worst compactness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.065161</td>\n",
       "      <td>worst concavity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.808945</td>\n",
       "      <td>worst concave points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.193993</td>\n",
       "      <td>worst symmetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>worst fractal dimension</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coefs                 features\n",
       "0   0.000000              mean radius\n",
       "1   0.000000             mean texture\n",
       "2   0.000000           mean perimeter\n",
       "3   0.000000                mean area\n",
       "4   0.000000          mean smoothness\n",
       "5   0.000000         mean compactness\n",
       "6   0.000000           mean concavity\n",
       "7  -0.629997      mean concave points\n",
       "8   0.000000            mean symmetry\n",
       "9   0.000000   mean fractal dimension\n",
       "10 -0.514483             radius error\n",
       "11  0.000000            texture error\n",
       "12  0.000000          perimeter error\n",
       "13  0.000000               area error\n",
       "14  0.000000         smoothness error\n",
       "15  0.000000        compactness error\n",
       "16  0.000000          concavity error\n",
       "17  0.000000     concave points error\n",
       "18  0.000000           symmetry error\n",
       "19  0.000000  fractal dimension error\n",
       "20 -2.348455             worst radius\n",
       "21 -0.694616            worst texture\n",
       "22  0.000000          worst perimeter\n",
       "23  0.000000               worst area\n",
       "24 -0.257861         worst smoothness\n",
       "25  0.000000        worst compactness\n",
       "26 -0.065161          worst concavity\n",
       "27 -0.808945     worst concave points\n",
       "28 -0.193993           worst symmetry\n",
       "29  0.000000  worst fractal dimension"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_l1_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Regression model metric $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.740607742865\n"
     ]
    }
   ],
   "source": [
    "# Regression typically uses R2 as its metric.\n",
    "# R2 is the amount of variance in Y explained by your model over the variance \n",
    "# explained by the mean model, or intercept model.\n",
    "\n",
    "# Get the R2 (on the data we trained on... R2 is in this case an \"inflated\"\n",
    "# estimation of how much variance we will explain for new data. This is\n",
    "# why we use cross-validation.)\n",
    "print house_linreg.score(Xh_mat, Yh)\n",
    "\n",
    "# 1 is the maximum for R2\n",
    "# 0 is the minimum for R2 (when testing on the training data)\n",
    "\n",
    "# NOTE: you may have seen R2 that are negative..\n",
    "# This can happend when you test your model on held-out data\n",
    "# What does a negative R2 mean?\n",
    "# This means the model is worse at predicting Y than just using the mean of Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification metrics:\n",
    "\n",
    "Classification metrics are more various. This is because we can have priorities about how many true positives, false positives we want. Review the classification metrics lecture for this to review in depth.\n",
    "\n",
    "- Accuracy if we just want to get the best proportion of correct guesses to incorrect guesses.\n",
    "- If you don't many false negatives (as in telling someone they have cancer or not), then accuracy is probably not what you want to optimize for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98769771529\n"
     ]
    }
   ],
   "source": [
    "# fit normally and calculate the accuracy\n",
    "lr_std_mod = lr_standard.fit(Xb_mat, Yb)\n",
    "print lr_std_mod.score(Xb_mat, Yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9826087   0.97391304  0.97345133  0.97345133  0.99115044]\n",
      "0.978914967295\n"
     ]
    }
   ],
   "source": [
    "# cross-validate the accuracy:\n",
    "# CROSS-VALIDATION\n",
    "# if we test on the data we trained on, then we are not getting a good sense\n",
    "# of how well it will perform on new data.\n",
    "# Cross-validation splits up the data you have, it trains on a fraction of\n",
    "# the data, then scores it on the data you held out.\n",
    "#\n",
    "# Why is this better?\n",
    "# Your model will necessarily perform the best it can on your own data, because\n",
    "# the model literally optimizedd the predictor coefficients to get as close\n",
    "# to the target values as possible.\n",
    "# If your current data is not representative of new data, it is likely to do\n",
    "# poorly. SO your estimation of performance is inflated.\n",
    "#\n",
    "# With cross-validation, you are EMULATING having new data, by leavinng out\n",
    "# data as if it were new, then scoring on that.\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(lr_std_mod, Xb_mat, Yb, cv=5)\n",
    "\n",
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,) (569,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207</td>\n",
       "      <td>5</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>209</td>\n",
       "      <td>360</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1  All\n",
       "True                    \n",
       "0          207    5  212\n",
       "1            2  355  357\n",
       "All        209  360  569"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the confusion matrix, TP, TN, FP, FN\n",
    "y_pred = lr_std_mod.predict(Xb_mat)\n",
    "print y_pred.shape, Yb.shape\n",
    "\n",
    "pd.crosstab(Yb, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we want to have no false negatives. We don't want to tell someone they don't\n",
    "# have cancer when they actually do!\n",
    "\n",
    "# How to do this?\n",
    "# First get the model's predicted probabilities of each class.\n",
    "predicted_probabilities = lr_std_mod.predict_proba(Xb_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.99999999e-01   1.03870491e-09]\n",
      " [  9.99970076e-01   2.99244560e-05]\n",
      " [  9.99999845e-01   1.55415263e-07]\n",
      " [  9.99538770e-01   4.61230056e-04]\n",
      " [  9.99972364e-01   2.76357028e-05]]\n"
     ]
    }
   ],
   "source": [
    "print predicted_probabilities[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 569\n"
     ]
    }
   ],
   "source": [
    "# change the threshold for deciding whether something is 0:\n",
    "# we want to be 95 percent confident a person doesnt have cancer to say they dont,\n",
    "# instead of the standard if over 50% confident they don't say they dont.\n",
    "y_new_pred = [0 if pp[0] > 0.95 else 1 for pp in predicted_probabilities]\n",
    "print len(Yb), len(y_new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181</td>\n",
       "      <td>31</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>181</td>\n",
       "      <td>388</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1  All\n",
       "True                    \n",
       "0          181   31  212\n",
       "1            0  357  357\n",
       "All        181  388  569"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(np.array(Yb), np.array(y_new_pred),\n",
    "            rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
