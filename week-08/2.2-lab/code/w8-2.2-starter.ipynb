{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisiting MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you recall, for linear regressions, we estimate parameters by deploying some kind of least square technique, the usual suspect being the ordinary least squares (OLS). However, a logistic regression breaks one of the cardinal assumptions of OLS, namely the normality of the target (dependent) variable, given the fact that logistics are binary. \n",
    "\n",
    "Therefore, you'll recall that we have to deploy the apparatus of the MLE to do parameter estimation for the right-hand side of the equation. Recall that MLE seek to find the maximum probability given the data at hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you recall, MLE's require a few ingredients, one is a well-defined likelihood function. Given, the fact that we are dealing with binary targets, we can easily model these using Bernoulli scheme: $$ P(x_i)^{r_i}(1-P(x_i)^{1-r_i})$$\n",
    "\n",
    "Recall also that we seek to maximize the following: $$\\prod_{i=1}^n P(x_i)^{r_i}(1-P(x_i)^{1-r_i})$$, yet because off the annoying property of computing the derivatives numerically, it's best to transform this with the logarithm, which makes this into computing a derivative of a product chain to computing a derivative of a sum: $$\\sum_{i=1}^n [r_i * ln(P(x_i)) + (1-r_i)ln(1-P(x_i))]$$\n",
    "\n",
    "A much \"cleaner\" functional form with respect to computing a derivative. From here, the problem is transferred to solving a constraint optimization problem. Rarely will you have to do this by hand, and we did some simple finger exercises previously for you to get the feel of it, but in general, the software will handle these in the background for you.\n",
    "\n",
    "For those of you with the mathematical background, you should check up iterative numerical methods for least square problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful reserved words/functions in the Stan environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Remember** The Docs are your friends, use them, study them, read them always, at night, in the mornings, while you're eating lunch, while you're taking care of your baby, while you're on a date... **ALWAYS**. \n",
    "\n",
    "http://pystan.readthedocs.io/en/latest/api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reintroducing the Polling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This case study will be based off of the data we used in Lab 1.4: http://www.stat.columbia.edu/~gelman/arm/examples/election88/, from the great one, Dr. Gelman, one of the foremost researchers in Bayesian analysis.\n",
    "Recall, this election was ultimately a major victory for the Grand Old Party (GOP/Republicans), and propelled George H.W. Bush (the father of George W. Bush) into the presidency.\n",
    "Import the data, and delete the Unnamed column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and check the first few observations to get a view of the data. Basically do what you did in the previous lab, you should be a champ at this by now !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pystan",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2feccf991d8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named pystan"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pystan\n",
    "import os\n",
    "import pylab as py\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%precision 4\n",
    "plt.style.use('ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the same length of the data set (you will) so you know the file hasn't changed (at least with respect to length). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Logistic Regression in PyStan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going use the old polling data differently today, we're going to build a bush-classifier. What does that mean? Since we have a column of data that is 1 for a polled for Bush, and 0 otherwise, we'll see if any of the data in the table are good predictors for someone who ended up polling for Papa Bush. \n",
    "\n",
    "The point of this exercise is not really to build a good predictor, but to gain more facility with the PyStan environment. So we're going to make some unrealstic assumptions in this first run so we can just get use to producing/constructing models with PyStan. \n",
    "\n",
    "For the PyStan model below, I want you to assume that all your parameters are normally distributed with 0 mean and variance 10. Realistic? No way. But it'll make the model specification go smoother. For those of you who want a challenge, after you get your first model working. Go back and think about what distributions you should use instead of normal to get a better fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the PyStan Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_reg_code = \"\"\"\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dictionary for the 2-variate Pystan Logistic Regression and setup the Pystan model from the STAN C++ code written above, also print the model to observe the quartile and other summary stats. After, output the traceplot to observe the parameter graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct your model as you did with the Bayesian regression yesterday (remember this is where you combine your model gode, your data, and determine how many jobs and iterations you'll have, as well as chains. For our purposes, set n_jobs = 1, iter = 1000, and chains = 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Note - we set chains = 1 for Windows environ since PyStan dev have not thoroughly tested multi-threading in Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the traceplot of the model. What do you see? Is it a good mix or a bad one? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Build a scatter plot view of the traceplot of the parameters. **Hint**, the easiest way is probably to put the model components, a, b, the coeffecients, and the constant in a pandas dictionary, and then call the pandas method scatter_matrix. **Another Hint**: look up the .extract() method in the PyStan docs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the coefficients from the model (read the PyStan docs if you don't know the method for this procedure, but if you did the above exercise, you should pretty much know how to do it). House those extracted coefficients in a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is something we haven't done last time. We're going to build a predictor function. For this we need to define a python function, and remember, for Bayesian models, we need to specify the function explicitly, and we're going to build a function that predits a logistic regression, so how should that look like? \n",
    "\n",
    "Also note, we are really just a simple type of \"forecasting\", we're not doing any validation (so not test/train sets), we're just excploring what kind of things we can possibly do with PyStan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the predFunction to graph the function on a X-Y axis. First define the x-axis using linspace form numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the coeffecient medians to predFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the function using pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
