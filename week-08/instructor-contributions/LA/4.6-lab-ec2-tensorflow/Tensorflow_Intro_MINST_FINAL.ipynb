{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Introduction to Tensorflow and MNIST\n",
    "*Citation: Google Tensorflow Introduction: MNIST for Beginners, What's an MNIST by Mike Bernico*\n",
    "\n",
    "The MNIST database (Mixed National Institute of Standards database) is a large database of handwritten digits commonly used for training various processing system. The database is also used for training and testing in the machine learning. It was created by \"re-mixing\" the samples from NIST's original datasets. The creators felt that since NIST's training dataset was taken from American Census Bureau employees, while the testing dataset was taken from American high school students, it was not well-suited for machine learning experiments. Furthermore, the black and white images from NIST were normalized to fit into a 20x20 pixel bounding box and anti-aliased, which introduced grayscale levels. [Wikipedia](https://en.wikipedia.org/wiki/MNIST_database)\n",
    "\n",
    "Consider MNIST as the \"hello world\" of computer vision\n",
    "\n",
    "**Objectives Today:** \n",
    "- Setup tensorflow in an ubuntu ec2 environments. This will allow for you to scale your computing power.\n",
    "- Run tensorflow basic introduction on mnist\n",
    "- Review examples and applications of tensorflow currently\n",
    "\n",
    "\n",
    "**MNIST Resource List**\n",
    "- Google Tutorial: \n",
    "- [Sklearn MNIST Tutorial](http://scikit-learn.org/stable/tutorial/basic/tutorial.html#introduction)\n",
    "- [Skleanrn MNIST Output](http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html) Review to give us context of tensorflow within our current learning environment\n",
    "- [Lasagne](http://lasagne.readthedocs.io/en/latest/user/tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting images to matrices\n",
    "\n",
    "![](./images/vl_mnist_knn.png)\n",
    "\n",
    "[view youtube video](https://www.youtube.com/watch?v=ZD_tfNpKzHY)\n",
    "\n",
    "__Scipy provides a method to convert images such as png to a matrix: [scipy.misc.imread()](http://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.imread.html)__\n",
    "\n",
    "    imread uses the Python Imaging Library (PIL) to read an image. The following notes are from the PIL documentation.\n",
    "\n",
    "    mode can be one of the following strings:\n",
    "\n",
    "    - ‘L’ (8-bit pixels, black and white)\n",
    "    - ‘P’ (8-bit pixels, mapped to any other mode using a color palette)\n",
    "    - ‘RGB’ (3x8-bit pixels, true color)\n",
    "    - ‘RGBA’ (4x8-bit pixels, true color with transparency mask)\n",
    "    - ‘CMYK’ (4x8-bit pixels, color separation)\n",
    "    - ‘YCbCr’ (3x8-bit pixels, color video format)\n",
    "    - ‘I’ (32-bit signed integer pixels)\n",
    "    - ‘F’ (32-bit floating point pixels\n",
    "    \n",
    "** We will see this in tensorflow image library as well**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare various algorithsm for MNIST Classification, Handwritten Digit Classification\n",
    "\n",
    "Read about the variety of results, given different transformations of the MINST dataset, [Classification datasets results](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)\n",
    "\n",
    "From the wikipedia page: \n",
    "![](./images/wiki-mnisttable.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#potential error fixed with \"sudo apt-get install libsm6 libxrender1 libfontconfig1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "sess = tf.InteractiveSession()\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Training set:  (55000, 784)\n",
      "This is the Training labels:  (55000, 10)\n",
      "This is the Testing set:  (10000, 784)\n",
      "This is the Testing labels:  (10000, 784)\n",
      "This is the Validation set:  (5000, 784)\n"
     ]
    }
   ],
   "source": [
    "#let's look at the dataset shape\n",
    "# CHECK: Why are their 10 labels? What method is used here?\n",
    "# CHECK: What is a validation set?\n",
    "print \"This is the Training set: \", mnist.train.images.shape\n",
    "print \"This is the Training labels: \", mnist.train.labels.shape\n",
    "print \"This is the Testing set: \", mnist.test.images.shape\n",
    "print \"This is the Testing labels: \", mnist.test.images.shape\n",
    "print \"This is the Validation set: \", mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set\n",
    "\n",
    "What are the ways we used for model validation?\n",
    "- Train/Test Split\n",
    "- K-Fold CV\n",
    "\n",
    "This set uses another method: \"Train/Validation/Test\" \n",
    "\n",
    "**Why this other method?**\n",
    "- Test set is a pure hold out set that the model has never seen\n",
    "- K-Fold CV is a great choice\n",
    "- Biggest limit in deep learning so K-Fold CV may not be available\n",
    "- Biggest validation in text set, the better. Thus you need a lot more data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.38039219,  0.37647063,  0.3019608 ,\n",
       "        0.46274513,  0.2392157 ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.35294119,  0.5411765 ,  0.92156869,\n",
       "        0.92156869,  0.92156869,  0.92156869,  0.92156869,  0.92156869,\n",
       "        0.98431379,  0.98431379,  0.97254908,  0.99607849,  0.96078438,\n",
       "        0.92156869,  0.74509805,  0.08235294,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.54901963,\n",
       "        0.98431379,  0.99607849,  0.99607849,  0.99607849,  0.99607849,\n",
       "        0.99607849,  0.99607849,  0.99607849,  0.99607849,  0.99607849,\n",
       "        0.99607849,  0.99607849,  0.99607849,  0.99607849,  0.99607849,\n",
       "        0.74117649,  0.09019608,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.88627458,  0.99607849,  0.81568635,\n",
       "        0.78039223,  0.78039223,  0.78039223,  0.78039223,  0.54509807,\n",
       "        0.2392157 ,  0.2392157 ,  0.2392157 ,  0.2392157 ,  0.2392157 ,\n",
       "        0.50196081,  0.8705883 ,  0.99607849,  0.99607849,  0.74117649,\n",
       "        0.08235294,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.14901961,  0.32156864,  0.0509804 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.13333334,\n",
       "        0.83529419,  0.99607849,  0.99607849,  0.45098042,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.32941177,  0.99607849,\n",
       "        0.99607849,  0.91764712,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.32941177,  0.99607849,  0.99607849,  0.91764712,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.41568631,  0.6156863 ,\n",
       "        0.99607849,  0.99607849,  0.95294124,  0.20000002,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.09803922,  0.45882356,  0.89411771,  0.89411771,\n",
       "        0.89411771,  0.99215692,  0.99607849,  0.99607849,  0.99607849,\n",
       "        0.99607849,  0.94117653,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.26666668,  0.4666667 ,  0.86274517,\n",
       "        0.99607849,  0.99607849,  0.99607849,  0.99607849,  0.99607849,\n",
       "        0.99607849,  0.99607849,  0.99607849,  0.99607849,  0.55686277,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.14509805,  0.73333335,\n",
       "        0.99215692,  0.99607849,  0.99607849,  0.99607849,  0.87450987,\n",
       "        0.80784321,  0.80784321,  0.29411766,  0.26666668,  0.84313732,\n",
       "        0.99607849,  0.99607849,  0.45882356,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.44313729,  0.8588236 ,  0.99607849,  0.94901967,  0.89019614,\n",
       "        0.45098042,  0.34901962,  0.12156864,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.7843138 ,  0.99607849,  0.9450981 ,\n",
       "        0.16078432,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.66274512,  0.99607849,\n",
       "        0.6901961 ,  0.24313727,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.18823531,\n",
       "        0.90588242,  0.99607849,  0.91764712,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.07058824,  0.48627454,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.32941177,  0.99607849,  0.99607849,\n",
       "        0.65098041,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.54509807,  0.99607849,  0.9333334 ,  0.22352943,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.82352948,  0.98039222,  0.99607849,\n",
       "        0.65882355,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.94901967,  0.99607849,  0.93725497,  0.22352943,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.34901962,  0.98431379,  0.9450981 ,\n",
       "        0.33725491,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.01960784,\n",
       "        0.80784321,  0.96470594,  0.6156863 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01568628,  0.45882356,  0.27058825,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out matrix for first image in tensorflow \n",
    "mnist.train.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What happened to the image? It was flattened out\n",
    "\n",
    "mnist.train.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Can we change the size of the image? \n",
    "a = np.reshape(mnist.train.images[0], [28,28])\n",
    "print a.shape\n",
    "#print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc3c16fd710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzVUzTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3c4c86dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's see what this image looks like\n",
    "# Matrix can be described as a mapping of pixel intensity\n",
    "# What happens when we add color? We add a dimension.\n",
    "\n",
    "plt.imshow(a, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implementation of tensorflow from Google tutorial with neural networks below\n",
    "#Follow along here: https://www.tensorflow.org/versions/0.6.0/tutorials/mnist/beginners/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9185\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logistic regression using tensorflow -- work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    # variables_\n",
    "    batch_size = 120 \n",
    "    beta = .001 #regularization\n",
    "    image_size = 28\n",
    "    num_labels = 10\n",
    "\n",
    "    # at run time with a training minibatch\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf.valid_dataset = tf.constant(mnist.validation.images)\n",
    "    tf.test_dataset = tf.constant(mnist.test.images)\n",
    "    \n",
    "    #weights and biases for output/logit layer\n",
    "    w_logit = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    b_logit = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "def model(data):\n",
    "    '''\n",
    "    Assembles the NM\n",
    "    '''\n",
    "    return tf.matmul(data, w_logit) + b_logit #return the output layer, tf matrix multiplication\n",
    "\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#Training Computations\n",
    "logits = model(tf_train_dataset)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) #compare training with actual\n",
    "regularized_loss = tf.nn.l2_loss(w_logit)\n",
    "total_loss = loss + beta * regularized_loss\n",
    "\n",
    "#Optimizer - bug in code prevents from running correctly\n",
    "#optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# #Predictions \n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "valid_prediction = tf.nn.softmax(model(tf.valid_dataset))\n",
    "test_prediction = tf.nn.softmax(model(tf.test_dataset))\n",
    "\n",
    "loss\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions,1) == np.argmax(labels, 1)))\n",
    "\n",
    "total_loss\n",
    "\n",
    "num_steps = 5001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialize\")\n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        # Generate a minibatch\n",
    "        batch_data, batch_labels = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # Prepare a dictionary telling the sesion where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed, \n",
    "        # and the value is the numpy array to feed it\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.lf%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.lf%%\" % accuracy(valid_prediction.eval(), \n",
    "                                                           mnist.validation.labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_predication.eval(), mnist.text.labels))\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    valid_prediction.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
