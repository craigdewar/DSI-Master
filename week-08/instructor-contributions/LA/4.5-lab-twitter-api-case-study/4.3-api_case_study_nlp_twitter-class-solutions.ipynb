{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "---\n",
    "title: API Case Study with Twitter\n",
    "type:  lesson + lab + demo\n",
    "duration: \"1:25\"\n",
    "creator:\n",
    "    name: David Yerrington\n",
    "    city: SF\n",
    "---\n",
    "```\n",
    "<img src=\"https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png\" style=\"float: left; margin: 10px\">\n",
    "\n",
    "#  API Demo / Lab + NLP\n",
    "Week 8 | 3.3\n",
    "\n",
    "\n",
    "<img src=\"https://snag.gy/RNAEgP.jpg\" width=\"600\">\n",
    "\n",
    "Can we correctly identify which of these two old men tweeted what?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5 mins) Opening \n",
    "\n",
    "Today we are going to attempt to classify wether a tweet comes from Trump, or Sanders.  We are going to:\n",
    "\n",
    "- Create a developer account on Twitter\n",
    "- Create a method to pull a list of tweets from the Twitter API\n",
    "- Perform proper preprocessing on our text\n",
    "- Engineer sentiment feature in our dataset using TextBlob\n",
    "- Explore supervised classification techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter API Developer Registration\n",
    "\n",
    "If you haven't registered a Twitter account yet, this is a requirement in order to have a \"developer\" account.\n",
    "\n",
    "[Twitter Rest API](https://dev.twitter.com/rest/public)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an \"App\"\n",
    "\n",
    "![](https://snag.gy/HPBQbJ.jpg)\n",
    "\n",
    "We now will now go to Twitter and register an \"app\" [apps.twitter.com](https://apps.twitter.com/), just like we did for Foursquare.  After we set up our app, we will only need to reference the cooresponding keys Twitter generates for our app.  These are the keys that we will use with our application to communicate with the Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python Twitter API library\n",
    "\n",
    "Someone was nice enough to build a nice libary for us in Python that we only need to plug in our keys and start collecting data with.  The library we will be using is provided by [Python Twitter Tools](http://mike.verdone.ca/twitter/).\n",
    "\n",
    "To install it, just run the next frame (there is no conda package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): twitter in /Users/powchow/.virtualenvs/gatech-ml/lib/python2.7/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): python-twitter in /Users/powchow/.virtualenvs/gatech-ml/lib/python2.7/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): future in /Users/powchow/.virtualenvs/gatech-ml/lib/python2.7/site-packages (from python-twitter)\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests in /Users/powchow/.virtualenvs/gatech-ml/lib/python2.7/site-packages (from python-twitter)\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests-oauthlib in /Users/powchow/.virtualenvs/gatech-ml/lib/python2.7/site-packages (from python-twitter)\n",
      "Cleaning up...\n"
     ]
    }
   ],
   "source": [
    "!pip install twitter python-twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Boring Twitter Rules\n",
    "\n",
    "Twitter says they will rate limit your requests:\n",
    "\n",
    ">When using application-only authentication, rate limits are determined globally for the entire application. If a method allows for 15 requests per rate limit window, then it allows you to make 15 requests per window — on behalf of your application. This limit is considered completely separately from per-user limits. https://dev.twitter.com/rest/public/rate-limiting\n",
    "\n",
    "Here's a quick overview of what Twitter says are \"the rulez\":\n",
    "\n",
    "![](https://snag.gy/yJ6vIH.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About those Keys: OAuth Review\n",
    "\n",
    "![](https://g.twimg.com/dev/documentation/image/appauth_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's going on here?  Take a minute.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Application Keys\n",
    "\n",
    "Take note of our application keys that we will be using with our little application that will be connecting to Twitter and mining Tweets from the official Bernie Sanders and Donald Trump twitter accounts.\n",
    "\n",
    "![](https://snag.gy/H1djQK.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Miner Class Setup\n",
    "\n",
    "The following code is meant to get us up and running with connectivity to twitter, and the ability to make requests and easily transform the JSON responses to DataFrames.  We will be using object oriented Python in order to organize our code.  We may go into review since this was a topic we covered earlier in the class but we can review it during the lab for those who want to know more about it.\n",
    "\n",
    "\n",
    "> \"request_limit\" is used in this class to limit the number of tweets that are pulled per instance request.  Setting it to something lower until you've worked the bugs out of your request, and captured the data you want, is essential to avoiding any rate limit blocks.\n",
    "\n",
    "#### Key Setup\n",
    "\n",
    "- **consumer_key** - Find this in your app page under the \"Keys and Access Tokens\"\n",
    "- **consumer_secret** - Right under **consumer_key** in the \"Keys and Access Tokens\" tab\n",
    "- **access_token_key** - You will need to click the \"generate tokens\" button to get this\n",
    "- **access_token_secret** - Also available after \"generate tokens\" is pressed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Remember to create a \"twitter_user_keys.py\" in the same directory. Store a json with all your information from above: \n",
    "\n",
    "twitter_keys ={\n",
    "'consumer_key': '',\n",
    "'consumer_secret': '',\n",
    "'access_token_key ':'',\n",
    "'access_token_secret ':''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!cat twitter_user_keys.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @SeanMcElwee: New research: decline of manufacturing and free trade are not driving Trump support. https://t.co/ydGMuRwuqg https://t.co/…\n",
      "#Zika transmission in #Florida has led the @FDA_Drug_Info to halt blood collection https://t.co/mUdFLnbsNk https://t.co/7X81azst5p\n",
      "Now I'm going to get in my car and deposit my Microsoft paycheck on the way home.\n",
      "#DataScience for Beginners 2: Is your #data ready? https://t.co/Rp21GOcfzx https://t.co/IUKEmVfSxX\n",
      "(Also what happened to @SimonJackman's blog?)\n",
      "RT @hacks4pancakes: @SwiftOnSecurity @johnnysunshine We shouldn't have to reverse engineer system function (in ways that could break the OS…\n",
      "RT @Khanoisseur: this is an astonishing chart https://t.co/RmLFbEgQPb\n",
      "It's interesting how Pat Toomey and Jeff Flake were right-wing bomb-throwers in the House but AFAIK not in the Senate. (Is that right?)\n",
      "RT @byron_auguste: If you can do the job, you should get the job. @OpptyatWork\n",
      "\n",
      "Once we make it true, 'skills gap' days are numbered. https…\n",
      "Agreed. it was really nice to see and participate in the energy around the #IndustrialInternet and #Predix https://t.co/PgbTZn6hfb\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import twitter_user_keys as tk #create this file in your current directory\n",
    "\n",
    "consumer_key = tk.twitter_keys['consumer_key']\n",
    "consumer_secret = tk.twitter_keys['consumer_secret']\n",
    "access_token = tk.twitter_keys['access_token_key']\n",
    "access_secret = tk.twitter_keys['access_token_secret']\n",
    "\n",
    "#twitter_keys['access_token_secret'], twitter_keys['access_token_key'], twitter_keys['consumer_key'], twitter_keys['consumer_secret']))\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#check that I am accessing twitter through conencted twitter account\n",
    "for status in tweepy.Cursor(api.home_timeline).items(10):\n",
    "    # Process a single status\n",
    "    print(status.text) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import re, datetime, pandas as pd\n",
    "import json\n",
    "import twitter_user_keys as tk #create this file in your current directory\n",
    "\n",
    "class twitterminer():\n",
    "\n",
    "    request_limit   =   20    \n",
    "    api             =   False\n",
    "    data            =   []\n",
    "    \n",
    "    twitter_keys = {\n",
    "        'consumer_key':        tk.twitter_keys['consumer_key'],\n",
    "        'consumer_secret':     tk.twitter_keys['consumer_secret'],\n",
    "        'access_token_key':    tk.twitter_keys['access_token_key'],\n",
    "        'access_token_secret': tk.twitter_keys['access_token_secret']\n",
    "    }\n",
    "\n",
    "    def __init__(self,  request_limit = 20):\n",
    "        \n",
    "        self.request_limit = request_limit\n",
    "        \n",
    "        # This sets the twitter API object for use internall within the class\n",
    "        self.set_api()\n",
    "        \n",
    "    def set_api(self):\n",
    "        \n",
    "        auth = OAuthHandler(self.twitter_keys['consumer_key'], self.twitter_keys['consumer_secret'])\n",
    "        auth.set_access_token(self.twitter_keys['access_token_key'], self.twitter_keys['access_token_secret'])\n",
    "\n",
    "        self.api = tweepy.API(auth)\n",
    "\n",
    "    def mine_user_tweets(self, user=\"dyerrington\", mine_rewteets=False):\n",
    "\n",
    "        statuses   =   self.api.user_timeline(screen_name=user, count=self.request_limit)\n",
    "        data       =   []\n",
    "        \n",
    "        for item in statuses:\n",
    "\n",
    "            mined = {\n",
    "                'tweet_id': item.id,\n",
    "                'handle': item.user.name,\n",
    "                'retweet_count': item.retweet_count,\n",
    "                'text': item.text,\n",
    "                'mined_at': datetime.datetime.now(),\n",
    "                'created_at': item.created_at,\n",
    "            }\n",
    "            \n",
    "            data.append(mined)\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does anyone remember how we \"instantiate\" a new instance of this class?\n",
    "\n",
    "**Bonus bonus** How do we call the method to *mine_user_tweets()*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# twitter ids:  realDonaldTrump, berniesanders\n",
    "# Let's test this out here..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Now we create some training data\n",
    "\n",
    "We will have to munge a little bit in order to get our \"mined\" data from the Twitter API.  \n",
    "\n",
    " - Mine Trump Tweets\n",
    " - Create DataFrame\n",
    " - Mine Sanders Tweets\n",
    " - Append to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we only need to \"instantiate\" once.  Then we can call mine_user_tweets as much as we want.\n",
    "miner = twitterminer(request_limit=100)\n",
    "trump_tweets = miner.mine_user_tweets(\"realDonaldTrump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n",
      "{'handle': u'Donald J. Trump', 'mined_at': datetime.datetime(2016, 7, 28, 15, 59, 12, 128691), 'created_at': datetime.datetime(2016, 7, 28, 21, 38, 12), 'tweet_id': 758778607489708032, 'text': u'\"Dems warn not to underestimate Trump\\'s potential win\"\\nhttps://t.co/X3xHtjhHpB', 'retweet_count': 2182}\n"
     ]
    }
   ],
   "source": [
    "print type(trump_tweets[20])\n",
    "print trump_tweets[0]\n",
    "# parsed = json.load(trump_tweets)\n",
    "# print json.dumps(parsed, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-28 21:38:12</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 15:59:12.128691</td>\n",
       "      <td>2182</td>\n",
       "      <td>\"Dems warn not to underestimate Trump's potent...</td>\n",
       "      <td>758778607489708032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-28 21:08:32</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 15:59:12.128701</td>\n",
       "      <td>1781</td>\n",
       "      <td>Great to be back in Iowa! #TBT with @JerryJrFa...</td>\n",
       "      <td>758771144140820481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-28 20:56:09</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 15:59:12.128705</td>\n",
       "      <td>4272</td>\n",
       "      <td>Median household income is down for the middle...</td>\n",
       "      <td>758768028595032064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-28 20:31:59</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 15:59:12.128708</td>\n",
       "      <td>7776</td>\n",
       "      <td>A vote for Clinton-Kaine is a vote for TPP, NA...</td>\n",
       "      <td>758761945910669312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-28 20:30:18</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 15:59:12.128711</td>\n",
       "      <td>2010</td>\n",
       "      <td>AMERICA'S FUTURE\\nhttps://t.co/xymiA0Az7x</td>\n",
       "      <td>758761521317023744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-07-28 18:36:06</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 15:59:12.128714</td>\n",
       "      <td>3149</td>\n",
       "      <td>Bernie caved! https://t.co/xtcOnA8cw1</td>\n",
       "      <td>758732782348623874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-07-28 18:32:31</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 15:59:12.128720</td>\n",
       "      <td>4191</td>\n",
       "      <td>\"@LallyRay: Poll: Donald Trump Sees 17-Point P...</td>\n",
       "      <td>758731880183193601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-07-28 15:48:56</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 15:59:12.128723</td>\n",
       "      <td>2418</td>\n",
       "      <td>RT @mike_pence: Good morning! Join me in Lima,...</td>\n",
       "      <td>758690714268143616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-07-28 15:30:06</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 15:59:12.128726</td>\n",
       "      <td>12432</td>\n",
       "      <td>RT @piersmorgan: Trump makes a funny, obvious ...</td>\n",
       "      <td>758685974637473793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-07-28 15:10:35</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 15:59:12.128730</td>\n",
       "      <td>6045</td>\n",
       "      <td>RT @DRUDGE_REPORT: Obama Refers to Himself 119...</td>\n",
       "      <td>758681061786263552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at           handle                   mined_at  \\\n",
       "0 2016-07-28 21:38:12  Donald J. Trump 2016-07-28 15:59:12.128691   \n",
       "1 2016-07-28 21:08:32  Donald J. Trump 2016-07-28 15:59:12.128701   \n",
       "2 2016-07-28 20:56:09  Donald J. Trump 2016-07-28 15:59:12.128705   \n",
       "3 2016-07-28 20:31:59  Donald J. Trump 2016-07-28 15:59:12.128708   \n",
       "4 2016-07-28 20:30:18  Donald J. Trump 2016-07-28 15:59:12.128711   \n",
       "5 2016-07-28 18:36:06  Donald J. Trump 2016-07-28 15:59:12.128714   \n",
       "6 2016-07-28 18:32:31  Donald J. Trump 2016-07-28 15:59:12.128720   \n",
       "7 2016-07-28 15:48:56  Donald J. Trump 2016-07-28 15:59:12.128723   \n",
       "8 2016-07-28 15:30:06  Donald J. Trump 2016-07-28 15:59:12.128726   \n",
       "9 2016-07-28 15:10:35  Donald J. Trump 2016-07-28 15:59:12.128730   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0           2182  \"Dems warn not to underestimate Trump's potent...   \n",
       "1           1781  Great to be back in Iowa! #TBT with @JerryJrFa...   \n",
       "2           4272  Median household income is down for the middle...   \n",
       "3           7776  A vote for Clinton-Kaine is a vote for TPP, NA...   \n",
       "4           2010          AMERICA'S FUTURE\\nhttps://t.co/xymiA0Az7x   \n",
       "5           3149              Bernie caved! https://t.co/xtcOnA8cw1   \n",
       "6           4191  \"@LallyRay: Poll: Donald Trump Sees 17-Point P...   \n",
       "7           2418  RT @mike_pence: Good morning! Join me in Lima,...   \n",
       "8          12432  RT @piersmorgan: Trump makes a funny, obvious ...   \n",
       "9           6045  RT @DRUDGE_REPORT: Obama Refers to Himself 119...   \n",
       "\n",
       "             tweet_id  \n",
       "0  758778607489708032  \n",
       "1  758771144140820481  \n",
       "2  758768028595032064  \n",
       "3  758761945910669312  \n",
       "4  758761521317023744  \n",
       "5  758732782348623874  \n",
       "6  758731880183193601  \n",
       "7  758690714268143616  \n",
       "8  758685974637473793  \n",
       "9  758681061786263552  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_df = pd.DataFrame(trump_tweets)\n",
    "trump_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any interesting ngrams going on with Trump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'https co', 34),\n",
       " (u'crooked hillary', 18),\n",
       " (u'bernie sanders', 11),\n",
       " (u'hillary clinton', 9),\n",
       " (u'thank you', 6),\n",
       " (u'makeamericagreatagain https', 6),\n",
       " (u'to the', 6),\n",
       " (u'for the', 6),\n",
       " (u'tim kaine', 5),\n",
       " (u'the democratic', 5)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "# We can use the TfidfVectorizer to find ngrams for us\n",
    "vect = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Pulls all of trumps tweet text's into one giant string\n",
    "summaries = \"\".join(trump_df['text'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (10 mins) Try this exercize with Bernie Sanders.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sanders_tweets = miner.mine_user_tweets(\"berniesanders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets = pd.DataFrame(trump_tweets + sanders_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-28 04:00:23</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 00:14:05.273398</td>\n",
       "      <td>2701</td>\n",
       "      <td>\"@trumplican2016: @realDonaldTrump @DavidWohl ...</td>\n",
       "      <td>758512401629192192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-28 03:56:47</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 00:14:05.273407</td>\n",
       "      <td>3283</td>\n",
       "      <td>\"@DavidWohl: Barack is offended that @realDona...</td>\n",
       "      <td>758511494669664256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-28 02:42:13</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 00:14:05.273410</td>\n",
       "      <td>9583</td>\n",
       "      <td>Our country does not feel 'great already' to t...</td>\n",
       "      <td>758492727583576064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-28 02:39:07</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 00:14:05.273412</td>\n",
       "      <td>11009</td>\n",
       "      <td>Shooting deaths of police officers up 78% this...</td>\n",
       "      <td>758491947409481728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-28 00:01:31</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-07-28 00:14:05.273415</td>\n",
       "      <td>3176</td>\n",
       "      <td>Join me live in Toledo, Ohio!\\n#MakeAmericaGre...</td>\n",
       "      <td>758452289376022529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at           handle                   mined_at  \\\n",
       "0 2016-07-28 04:00:23  Donald J. Trump 2016-07-28 00:14:05.273398   \n",
       "1 2016-07-28 03:56:47  Donald J. Trump 2016-07-28 00:14:05.273407   \n",
       "2 2016-07-28 02:42:13  Donald J. Trump 2016-07-28 00:14:05.273410   \n",
       "3 2016-07-28 02:39:07  Donald J. Trump 2016-07-28 00:14:05.273412   \n",
       "4 2016-07-28 00:01:31  Donald J. Trump 2016-07-28 00:14:05.273415   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0           2701  \"@trumplican2016: @realDonaldTrump @DavidWohl ...   \n",
       "1           3283  \"@DavidWohl: Barack is offended that @realDona...   \n",
       "2           9583  Our country does not feel 'great already' to t...   \n",
       "3          11009  Shooting deaths of police officers up 78% this...   \n",
       "4           3176  Join me live in Toledo, Ohio!\\n#MakeAmericaGre...   \n",
       "\n",
       "             tweet_id  \n",
       "0  758512401629192192  \n",
       "1  758511494669664256  \n",
       "2  758492727583576064  \n",
       "3  758491947409481728  \n",
       "4  758452289376022529  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing our Tweets\n",
    "\n",
    "In order to do classfication recall that we need a set of features.  Our features are literally what our presidential hopefulls say on Twitter. \n",
    "\n",
    "We will need to:\n",
    "- Vectorize input text data\n",
    "- Intialize a model (let's try Logistic regression)\n",
    "- Train / Predict / Cross Validate\n",
    "- Score / Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Preprocess our text data to Tfidf\n",
    "tfv = TfidfVectorizer(lowercase=True, strip_accents='unicode')\n",
    "X_all = tfv.fit_transform(all_tweets['text'])\n",
    "\n",
    "# Setup logistic regression (or try another classification method here)\n",
    "estimator = LogisticRegression()\n",
    "estimator.fit(X_all, all_tweets['handle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Prediction vs Random Sanders Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.54453967,  0.45546033],\n",
       "       [ 0.34520049,  0.65479951]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep our source as TfIdf vectors\n",
    "source_test = [\n",
    "    \"Demanding that the wealthy and the powerful start paying their fair share of taxes that's exactly what the American people want.\",\n",
    "    \"Crooked Hillary is spending tremendous amounts of Wall Street money on false ads against me. She is a very dishonest person!\"\n",
    "]\n",
    "\n",
    "############\n",
    "# NOTE:  Do not re-initialize the tfidf vectorizor or the feature space willbe overwritten and\n",
    "# hence your transform will not match the number of features you trained your model on.\n",
    "#\n",
    "# This is why you only need to \"transform\" since you already \"fit\" previously\n",
    "#\n",
    "####\n",
    "\n",
    "X_all = tfv.transform(source_test)\n",
    "\n",
    "# Predict using previously trained logist regression `estimator`\n",
    "estimator.predict_proba(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Thanks Mike Frantz!!! This function will help you clean your string\n",
    "\n",
    "def cleaner( text ):\n",
    "    from bs4 import BeautifulSoup\n",
    "    from nltk.corpus import stopwords\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(text).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!!! Thanks Isaac\n",
    "\n",
    "import pandas as pd, seaborn as sns, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# encoding handles\n",
    "handles = []\n",
    "for i in all_tweets.handle:\n",
    "    if i == 'Bernie Sanders':\n",
    "        handles.append(1)\n",
    "    else:\n",
    "        handles.append(0)\n",
    "print handles\n",
    "\n",
    "all_tweets['bin_handles'] = handles\n",
    "all_tweets.head()\n",
    "\n",
    "def the_normalizer(text):       \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    words = letters_only.lower().split()                             \n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")                 \n",
    "    meaningful_words = [w for w in all_tweets.text if not w in stopwords]   \n",
    "    return( \" \".join( meaningful_words ))\n",
    "\n",
    "y = all_tweets['bin_handles'].values\n",
    "X = all_tweets['text']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(y), test_size=0.33)\n",
    "\n",
    "cls = [MultinomialNB, BernoulliNB, RandomForestClassifier, LogisticRegression]\n",
    "for i in cls:\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(lowercase=True, strip_accents='unicode', stop_words=stop)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('cls', i())\n",
    "    ]) \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predicted = pipeline.predict(X_test)\n",
    "    print str(i), pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Time\n",
    "\n",
    "We would like you to perform an analysis using a proper cross validation.  Also, try classfication using other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implement the same analysis using more data.\n",
    "\n",
    "Experiment with using more data.  The API may not like that you are blowing through their limits so definitely be careful.  Try to grab only what you need 1x, then work on the copy of the objects that are returned.  Read the documents about rate limits and see if you can get enough without hitting the rate limit.  Are there any options available in the API to avoid such a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement K-Folds or test/train split.\n",
    "\n",
    "Double check that you are getting random data before moving forward.  What would happen if you over sample Trump more than Sanders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mine more Tweets that aren't in your data set\n",
    "Or use the hold-out method to do a proper test.  Refer back to our advanced classification evaluation lesson if you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check your classification report\n",
    "How's precision / recall of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Change out your TFIDF vectorizer for CountVectorizer.\n",
    "How has this impacted your mode performance at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Implement a different classification method such as random forrests.\n",
    "Or pick one of your favorites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  Try to remove stopwords from your text during your preprocessing step\n",
    "\n",
    "Then double check your classfication report.  Have things improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.  Try removing samples that have links or that are obviously just announcements or \"noise\" that doesn't appear to represent \"True\" tweets by the authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. What are some contrasting words or phrases that you can see between the ngrams for each author?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.  What do you think you can do to improve the scores further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. **BONUS** Using TextBlob, add a sentiment feature to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([u'@ trumplican2016', u'@ realdonaldtrump @', u'davidwohl', u'course mr trump', u'people'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(trump_tweets[0]['text']) #from originally provided trump tweets\n",
    "blob.tags           \n",
    "blob.noun_phrases   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextBlob(\"\"@ Trumplican2016: @realDonaldTrump @DavidWohl pasar la trompeta por supuesto mr su mensaje está resonando con el pueblo\"\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)\n",
    "\n",
    "blob.translate(to=\"es\")  # 'La amenaza titular de The Blob...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. BONUS BONUS Apply PCA to your text features\n",
    "Is this effective? (ie: we could talk about LDA here a little bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing\n",
    "\n",
    "- What where the most impactful changes that helped your models?\n",
    "- What do you think would happen if we had more Trump Tweets than Sanders?\n",
    "- What other projects might you think to apply these problems against?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
