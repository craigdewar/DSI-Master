{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines in SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/patricksmith/Desktop/stumbleupon.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>is_news</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  urlid  \\\n",
       "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "\n",
       "                                         boilerplate alchemy_category  \\\n",
       "0  {\"title\":\"IBM Sees Holographic Calls Air Breat...         business   \n",
       "\n",
       "  alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0               0.789131     2.055556           0.676471           0.205882   \n",
       "\n",
       "   commonlinkratio_3  commonlinkratio_4  ...    is_news  lengthyLinkDomain  \\\n",
       "0           0.047059           0.023529  ...          1                  1   \n",
       "\n",
       "   linkwordscore  news_front_page  non_markup_alphanum_characters  \\\n",
       "0             24                0                            5424   \n",
       "\n",
       "   numberOfLinks  numwords_in_url parametrizedLinkRatio  \\\n",
       "0            170                8              0.152941   \n",
       "\n",
       "   spelling_errors_ratio  label  \n",
       "0                0.07913      0  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with natural language processing (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', ''))\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    IBM Sees Holographic Calls Air Breathing Batte...\n",
       "1    The Fully Electronic Futuristic Starting Gun T...\n",
       "2    Fruits that Fight the Flu fruits that fight th...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = data['title'].fillna('')\n",
    "body = data['body'].fillna('')\n",
    "\n",
    "titles[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.51332\n",
       "0    0.48668\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts() / len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=True, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features = 1000, ngram_range=(1,2), stop_words='english',binary=True)\n",
    "\n",
    "vectorizer.fit(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'000',\n",
       " u'10',\n",
       " u'10 minutes',\n",
       " u'100',\n",
       " u'11',\n",
       " u'12',\n",
       " u'13',\n",
       " u'14',\n",
       " u'15',\n",
       " u'15 minutes',\n",
       " u'16',\n",
       " u'17',\n",
       " u'18',\n",
       " u'19',\n",
       " u'20',\n",
       " u'20 minutes',\n",
       " u'2008',\n",
       " u'2009',\n",
       " u'2010',\n",
       " u'2011',\n",
       " u'2012',\n",
       " u'21',\n",
       " u'22',\n",
       " u'23',\n",
       " u'24',\n",
       " u'25',\n",
       " u'26',\n",
       " u'28',\n",
       " u'30',\n",
       " u'30 minutes',\n",
       " u'35',\n",
       " u'350',\n",
       " u'350 degrees',\n",
       " u'40',\n",
       " u'400',\n",
       " u'45',\n",
       " u'50',\n",
       " u'60',\n",
       " u'ability',\n",
       " u'able',\n",
       " u'absolutely',\n",
       " u'according',\n",
       " u'actually',\n",
       " u'adapted',\n",
       " u'add',\n",
       " u'added',\n",
       " u'adding',\n",
       " u'addition',\n",
       " u'additional',\n",
       " u'advice',\n",
       " u'age',\n",
       " u'ago',\n",
       " u'ahead',\n",
       " u'air',\n",
       " u'allow',\n",
       " u'alternative',\n",
       " u'amazing',\n",
       " u'america',\n",
       " u'american',\n",
       " u'apart',\n",
       " u'apple',\n",
       " u'area',\n",
       " u'aren',\n",
       " u'art',\n",
       " u'article',\n",
       " u'aside',\n",
       " u'ask',\n",
       " u'asked',\n",
       " u'attention',\n",
       " u'author',\n",
       " u'available',\n",
       " u'average',\n",
       " u'avoid',\n",
       " u'away',\n",
       " u'awesome',\n",
       " u'baby',\n",
       " u'bacon',\n",
       " u'bad',\n",
       " u'bag',\n",
       " u'bake',\n",
       " u'baked',\n",
       " u'baking',\n",
       " u'baking powder',\n",
       " u'baking sheet',\n",
       " u'baking soda',\n",
       " u'ball',\n",
       " u'bar',\n",
       " u'base',\n",
       " u'based',\n",
       " u'basic',\n",
       " u'batter',\n",
       " u'beans',\n",
       " u'beat',\n",
       " u'beautiful',\n",
       " u'beauty',\n",
       " u'beef',\n",
       " u'begin',\n",
       " u'believe',\n",
       " u'benefits',\n",
       " u'best',\n",
       " u'better',\n",
       " u'big',\n",
       " u'bit',\n",
       " u'bite',\n",
       " u'black',\n",
       " u'blend',\n",
       " u'blog',\n",
       " u'blood',\n",
       " u'blue',\n",
       " u'board',\n",
       " u'body',\n",
       " u'boil',\n",
       " u'book',\n",
       " u'bought',\n",
       " u'bowl',\n",
       " u'box',\n",
       " u'brain',\n",
       " u'brand',\n",
       " u'bread',\n",
       " u'break',\n",
       " u'breakfast',\n",
       " u'bring',\n",
       " u'brown',\n",
       " u'brown sugar',\n",
       " u'brush',\n",
       " u'build',\n",
       " u'business',\n",
       " u'butter',\n",
       " u'buy',\n",
       " u'cake',\n",
       " u'cakes',\n",
       " u'california',\n",
       " u'called',\n",
       " u'calories',\n",
       " u'came',\n",
       " u'cancer',\n",
       " u'candy',\n",
       " u'car',\n",
       " u'care',\n",
       " u'carefully',\n",
       " u'case',\n",
       " u'cause',\n",
       " u'center',\n",
       " u'certain',\n",
       " u'certainly',\n",
       " u'chance',\n",
       " u'change',\n",
       " u'changes',\n",
       " u'check',\n",
       " u'cheese',\n",
       " u'chef',\n",
       " u'chicken',\n",
       " u'children',\n",
       " u'chips',\n",
       " u'chocolate',\n",
       " u'chocolate chips',\n",
       " u'choice',\n",
       " u'choose',\n",
       " u'chopped',\n",
       " u'cinnamon',\n",
       " u'city',\n",
       " u'class',\n",
       " u'classic',\n",
       " u'clean',\n",
       " u'clear',\n",
       " u'click',\n",
       " u'close',\n",
       " u'cloves',\n",
       " u'coat',\n",
       " u'coffee',\n",
       " u'cold',\n",
       " u'collection',\n",
       " u'college',\n",
       " u'color',\n",
       " u'com',\n",
       " u'combination',\n",
       " u'combine',\n",
       " u'combined',\n",
       " u'come',\n",
       " u'comes',\n",
       " u'coming',\n",
       " u'comment',\n",
       " u'comments',\n",
       " u'common',\n",
       " u'community',\n",
       " u'company',\n",
       " u'complete',\n",
       " u'completely',\n",
       " u'computer',\n",
       " u'consider',\n",
       " u'contact',\n",
       " u'container',\n",
       " u'content',\n",
       " u'continue',\n",
       " u'control',\n",
       " u'cook',\n",
       " u'cooked',\n",
       " u'cookie',\n",
       " u'cookies',\n",
       " u'cooking',\n",
       " u'cool',\n",
       " u'cool completely',\n",
       " u'corn',\n",
       " u'cost',\n",
       " u'couldn',\n",
       " u'country',\n",
       " u'couple',\n",
       " u'course',\n",
       " u'cover',\n",
       " u'covered',\n",
       " u'cream',\n",
       " u'cream cheese',\n",
       " u'creamy',\n",
       " u'create',\n",
       " u'created',\n",
       " u'creating',\n",
       " u'crisp',\n",
       " u'crust',\n",
       " u'cup',\n",
       " u'cups',\n",
       " u'current',\n",
       " u'currently',\n",
       " u'cut',\n",
       " u'cutting',\n",
       " u'daily',\n",
       " u'dark',\n",
       " u'date',\n",
       " u'day',\n",
       " u'days',\n",
       " u'deal',\n",
       " u'decided',\n",
       " u'deep',\n",
       " u'definitely',\n",
       " u'degrees',\n",
       " u'delicious',\n",
       " u'depending',\n",
       " u'design',\n",
       " u'designed',\n",
       " u'desired',\n",
       " u'dessert',\n",
       " u'desserts',\n",
       " u'developed',\n",
       " u'did',\n",
       " u'didn',\n",
       " u'diet',\n",
       " u'difference',\n",
       " u'different',\n",
       " u'difficult',\n",
       " u'dinner',\n",
       " u'dip',\n",
       " u'directions',\n",
       " u'directly',\n",
       " u'disease',\n",
       " u'dish',\n",
       " u'dishes',\n",
       " u'display',\n",
       " u'does',\n",
       " u'doesn',\n",
       " u'doing',\n",
       " u'don',\n",
       " u'don know',\n",
       " u'don want',\n",
       " u'double',\n",
       " u'dough',\n",
       " u'drain',\n",
       " u'dried',\n",
       " u'drink',\n",
       " u'drizzle',\n",
       " u'drop',\n",
       " u'dry',\n",
       " u'early',\n",
       " u'easier',\n",
       " u'easily',\n",
       " u'easy',\n",
       " u'eat',\n",
       " u'eating',\n",
       " u'edge',\n",
       " u'edges',\n",
       " u'effect',\n",
       " u'effective',\n",
       " u'effects',\n",
       " u'egg',\n",
       " u'eggs',\n",
       " u'electric',\n",
       " u'email',\n",
       " u'end',\n",
       " u'energy',\n",
       " u'enjoy',\n",
       " u'entire',\n",
       " u'especially',\n",
       " u'evenly',\n",
       " u'exactly',\n",
       " u'example',\n",
       " u'exercise',\n",
       " u'experience',\n",
       " u'extra',\n",
       " u'extract',\n",
       " u'eye',\n",
       " u'eyes',\n",
       " u'face',\n",
       " u'facebook',\n",
       " u'fact',\n",
       " u'fall',\n",
       " u'family',\n",
       " u'fan',\n",
       " u'far',\n",
       " u'fashion',\n",
       " u'fast',\n",
       " u'fat',\n",
       " u'favorite',\n",
       " u'features',\n",
       " u'feed',\n",
       " u'feel',\n",
       " u'feeling',\n",
       " u'feet',\n",
       " u'filled',\n",
       " u'filling',\n",
       " u'final',\n",
       " u'finally',\n",
       " u'fine',\n",
       " u'finely',\n",
       " u'finish',\n",
       " u'finished',\n",
       " u'firm',\n",
       " u'fish',\n",
       " u'fit',\n",
       " u'flat',\n",
       " u'flavor',\n",
       " u'flavors',\n",
       " u'flour',\n",
       " u'fluffy',\n",
       " u'fold',\n",
       " u'follow',\n",
       " u'following',\n",
       " u'food',\n",
       " u'food processor',\n",
       " u'foods',\n",
       " u'forget',\n",
       " u'form',\n",
       " u'forward',\n",
       " u'free',\n",
       " u'freezer',\n",
       " u'french',\n",
       " u'fresh',\n",
       " u'fridge',\n",
       " u'fried',\n",
       " u'friend',\n",
       " u'friendly',\n",
       " u'friends',\n",
       " u'frozen',\n",
       " u'fruit',\n",
       " u'fruits',\n",
       " u'fully',\n",
       " u'fun',\n",
       " u'function',\n",
       " u'funny',\n",
       " u'future',\n",
       " u'game',\n",
       " u'games',\n",
       " u'garlic',\n",
       " u'gave',\n",
       " u'general',\n",
       " u'gently',\n",
       " u'gets',\n",
       " u'getting',\n",
       " u'girl',\n",
       " u'given',\n",
       " u'gives',\n",
       " u'giving',\n",
       " u'glass',\n",
       " u'goes',\n",
       " u'going',\n",
       " u'golden',\n",
       " u'golden brown',\n",
       " u'gone',\n",
       " u'good',\n",
       " u'google',\n",
       " u'got',\n",
       " u'grated',\n",
       " u'great',\n",
       " u'green',\n",
       " u'ground',\n",
       " u'group',\n",
       " u'guess',\n",
       " u'guide',\n",
       " u'guy',\n",
       " u'guys',\n",
       " u'hair',\n",
       " u'half',\n",
       " u'hand',\n",
       " u'hands',\n",
       " u'happen',\n",
       " u'happy',\n",
       " u'hard',\n",
       " u'haven',\n",
       " u'having',\n",
       " u'head',\n",
       " u'health',\n",
       " u'healthy',\n",
       " u'heard',\n",
       " u'heart',\n",
       " u'heat',\n",
       " u'heavy',\n",
       " u'help',\n",
       " u'helps',\n",
       " u'high',\n",
       " u'high heat',\n",
       " u'higher',\n",
       " u'history',\n",
       " u'hit',\n",
       " u'hold',\n",
       " u'home',\n",
       " u'homemade',\n",
       " u'honey',\n",
       " u'hope',\n",
       " u'hot',\n",
       " u'hour',\n",
       " u'hours',\n",
       " u'house',\n",
       " u'http',\n",
       " u'huge',\n",
       " u'human',\n",
       " u'husband',\n",
       " u'ice',\n",
       " u'ice cream',\n",
       " u'idea',\n",
       " u'ideas',\n",
       " u'image',\n",
       " u'images',\n",
       " u'immediately',\n",
       " u'important',\n",
       " u'improve',\n",
       " u'inch',\n",
       " u'inches',\n",
       " u'include',\n",
       " u'included',\n",
       " u'including',\n",
       " u'increase',\n",
       " u'individual',\n",
       " u'information',\n",
       " u'ingredients',\n",
       " u'inside',\n",
       " u'inspired',\n",
       " u'instead',\n",
       " u'instructions',\n",
       " u'interesting',\n",
       " u'international',\n",
       " u'internet',\n",
       " u'isn',\n",
       " u'issue',\n",
       " u'italian',\n",
       " u'items',\n",
       " u'job',\n",
       " u'juice',\n",
       " u'just',\n",
       " u'keeping',\n",
       " u'key',\n",
       " u'kid',\n",
       " u'kids',\n",
       " u'kind',\n",
       " u'kitchen',\n",
       " u'knew',\n",
       " u'knife',\n",
       " u'know',\n",
       " u'known',\n",
       " u'large',\n",
       " u'large bowl',\n",
       " u'late',\n",
       " u'later',\n",
       " u'latest',\n",
       " u'layer',\n",
       " u'lead',\n",
       " u'learn',\n",
       " u'leave',\n",
       " u'leaves',\n",
       " u'leaving',\n",
       " u'left',\n",
       " u'lemon',\n",
       " u'let',\n",
       " u'let cool',\n",
       " u'level',\n",
       " u'levels',\n",
       " u'life',\n",
       " u'light',\n",
       " u'lightly',\n",
       " u'like',\n",
       " u'likely',\n",
       " u'line',\n",
       " u'lined',\n",
       " u'link',\n",
       " u'liquid',\n",
       " u'list',\n",
       " u'little',\n",
       " u'live',\n",
       " u'lives',\n",
       " u'living',\n",
       " u'll',\n",
       " u'local',\n",
       " u'long',\n",
       " u'longer',\n",
       " u'look',\n",
       " u'looked',\n",
       " u'looking',\n",
       " u'looks',\n",
       " u'lose',\n",
       " u'loss',\n",
       " u'lost',\n",
       " u'lot',\n",
       " u'lots',\n",
       " u'love',\n",
       " u'loved',\n",
       " u'low',\n",
       " u'lower',\n",
       " u'lunch',\n",
       " u'magazine',\n",
       " u'main',\n",
       " u'major',\n",
       " u'make',\n",
       " u'make sure',\n",
       " u'makes',\n",
       " u'making',\n",
       " u'man',\n",
       " u'march',\n",
       " u'market',\n",
       " u'matter',\n",
       " u'maybe',\n",
       " u'meal',\n",
       " u'meals',\n",
       " u'mean',\n",
       " u'means',\n",
       " u'meat',\n",
       " u'media',\n",
       " u'medical',\n",
       " u'medicine',\n",
       " u'medium',\n",
       " u'medium heat',\n",
       " u'medium high',\n",
       " u'melt',\n",
       " u'melted',\n",
       " u'men',\n",
       " u'method',\n",
       " u'microwave',\n",
       " u'middle',\n",
       " u'milk',\n",
       " u'million',\n",
       " u'mind',\n",
       " u'mini',\n",
       " u'minute',\n",
       " u'minutes',\n",
       " u'mix',\n",
       " u'mixed',\n",
       " u'mixer',\n",
       " u'mixing',\n",
       " u'mixture',\n",
       " u'model',\n",
       " u'models',\n",
       " u'mom',\n",
       " u'moment',\n",
       " u'money',\n",
       " u'month',\n",
       " u'months',\n",
       " u'morning',\n",
       " u'mother',\n",
       " u'mouth',\n",
       " u'multiple',\n",
       " u'music',\n",
       " u'national',\n",
       " u'natural',\n",
       " u'near',\n",
       " u'nearly',\n",
       " u'necessary',\n",
       " u'need',\n",
       " u'needed',\n",
       " u'needs',\n",
       " u'network',\n",
       " u'new',\n",
       " u'new york',\n",
       " u'news',\n",
       " u'nice',\n",
       " u'night',\n",
       " u'non',\n",
       " u'normal',\n",
       " u'note',\n",
       " u'number',\n",
       " u'nutrition',\n",
       " u'nuts',\n",
       " u'offer',\n",
       " u'oh',\n",
       " u'oil',\n",
       " u'old',\n",
       " u'olive',\n",
       " u'olive oil',\n",
       " u'ones',\n",
       " u'onion',\n",
       " u'onions',\n",
       " u'online',\n",
       " u'open',\n",
       " u'optional',\n",
       " u'orange',\n",
       " u'order',\n",
       " u'original',\n",
       " u'ounces',\n",
       " u'outside',\n",
       " u'oven',\n",
       " u'oven 350',\n",
       " u'oz',\n",
       " u'package',\n",
       " u'packed',\n",
       " u'page',\n",
       " u'pain',\n",
       " u'pan',\n",
       " u'paper',\n",
       " u'parchment',\n",
       " u'particular',\n",
       " u'parts',\n",
       " u'party',\n",
       " u'past',\n",
       " u'pasta',\n",
       " u'pay',\n",
       " u'peanut',\n",
       " u'peanut butter',\n",
       " u'people',\n",
       " u'pepper',\n",
       " u'percent',\n",
       " u'perfect',\n",
       " u'perfectly',\n",
       " u'person',\n",
       " u'personal',\n",
       " u'phone',\n",
       " u'photo',\n",
       " u'photography',\n",
       " u'photos',\n",
       " u'physical',\n",
       " u'pick',\n",
       " u'picture',\n",
       " u'pictures',\n",
       " u'pie',\n",
       " u'piece',\n",
       " u'pieces',\n",
       " u'pinch',\n",
       " u'pizza',\n",
       " u'place',\n",
       " u'plain',\n",
       " u'plan',\n",
       " u'plastic',\n",
       " u'plate',\n",
       " u'play',\n",
       " u'plenty',\n",
       " u'plus',\n",
       " u'point',\n",
       " u'pop',\n",
       " u'popular',\n",
       " u'position',\n",
       " u'possible',\n",
       " u'post',\n",
       " u'posted',\n",
       " u'posts',\n",
       " u'pot',\n",
       " u'potato',\n",
       " u'potatoes',\n",
       " u'pound',\n",
       " u'pounds',\n",
       " u'pour',\n",
       " u'powder',\n",
       " u'powdered',\n",
       " u'power',\n",
       " u'pre',\n",
       " u'prefer',\n",
       " u'preheat',\n",
       " u'preheat oven',\n",
       " u'prepare',\n",
       " u'prepared',\n",
       " u'press',\n",
       " u'pretty',\n",
       " u'prevent',\n",
       " u'print',\n",
       " u'probably',\n",
       " u'problem',\n",
       " u'problems',\n",
       " u'process',\n",
       " u'processor',\n",
       " u'produce',\n",
       " u'product',\n",
       " u'products',\n",
       " u'project',\n",
       " u'protein',\n",
       " u'provide',\n",
       " u'public',\n",
       " u'published',\n",
       " u'pull',\n",
       " u'pure',\n",
       " u'purpose',\n",
       " u'purpose flour',\n",
       " u'quality',\n",
       " u'question',\n",
       " u'quick',\n",
       " u'quickly',\n",
       " u'quite',\n",
       " u'rack',\n",
       " u'range',\n",
       " u'raw',\n",
       " u'reach',\n",
       " u'read',\n",
       " u'reading',\n",
       " u'ready',\n",
       " u'real',\n",
       " u'really',\n",
       " u'reason',\n",
       " u'recent',\n",
       " u'recently',\n",
       " u'recipe',\n",
       " u'recipes',\n",
       " u'recommend',\n",
       " u'red',\n",
       " u'reduce',\n",
       " u'refrigerate',\n",
       " u'refrigerator',\n",
       " u'regular',\n",
       " u'related',\n",
       " u'remaining',\n",
       " u'remember',\n",
       " u'remove',\n",
       " u'remove heat',\n",
       " u'repeat',\n",
       " u'research',\n",
       " u'researchers',\n",
       " u'rest',\n",
       " u'restaurant',\n",
       " u'result',\n",
       " u'results',\n",
       " u'return',\n",
       " u'rice',\n",
       " u'rich',\n",
       " u'right',\n",
       " u'risk',\n",
       " u'roasted',\n",
       " u'roll',\n",
       " u'room',\n",
       " u'room temperature',\n",
       " u'round',\n",
       " u'run',\n",
       " u'running',\n",
       " u'safe',\n",
       " u'said',\n",
       " u'salad',\n",
       " u'salt',\n",
       " u'salt pepper',\n",
       " u'salt1',\n",
       " u'sandwich',\n",
       " u'sauce',\n",
       " u'saucepan',\n",
       " u'save',\n",
       " u'saw',\n",
       " u'say',\n",
       " u'saying',\n",
       " u'says',\n",
       " u'school',\n",
       " u'science',\n",
       " u'search',\n",
       " u'season',\n",
       " u'second',\n",
       " u'seconds',\n",
       " u'secret',\n",
       " u'seeds',\n",
       " u'seen',\n",
       " u'self',\n",
       " u'send',\n",
       " u'sense',\n",
       " u'separate',\n",
       " u'seriously',\n",
       " u'serve',\n",
       " u'served',\n",
       " u'serves',\n",
       " u'serving',\n",
       " u'servings',\n",
       " u'set',\n",
       " u'set aside',\n",
       " u'shape',\n",
       " u'share',\n",
       " u'sheet',\n",
       " u'shop',\n",
       " u'short',\n",
       " u'shown',\n",
       " u'shows',\n",
       " u'sides',\n",
       " u'sign',\n",
       " u'similar',\n",
       " u'simmer',\n",
       " u'simple',\n",
       " u'simply',\n",
       " u'single',\n",
       " u'sit',\n",
       " u'site',\n",
       " u'size',\n",
       " u'sized',\n",
       " u'skillet',\n",
       " u'skin',\n",
       " u'sleep',\n",
       " u'slice',\n",
       " u'sliced',\n",
       " u'slices',\n",
       " u'slightly',\n",
       " u'slow',\n",
       " u'slowly',\n",
       " u'small',\n",
       " u'small bowl',\n",
       " u'smooth',\n",
       " u'snack',\n",
       " u'social',\n",
       " u'soda',\n",
       " u'soft',\n",
       " u'soon',\n",
       " u'sort',\n",
       " u'soup',\n",
       " u'sour',\n",
       " u'source',\n",
       " u'space',\n",
       " u'special',\n",
       " u'speed',\n",
       " u'spend',\n",
       " u'spent',\n",
       " u'spoon',\n",
       " u'sports',\n",
       " u'spray',\n",
       " u'spread',\n",
       " u'spring',\n",
       " u'sprinkle',\n",
       " u'stand',\n",
       " u'standard',\n",
       " u'star',\n",
       " u'start',\n",
       " u'started',\n",
       " u'starting',\n",
       " u'state',\n",
       " u'states',\n",
       " u'stay',\n",
       " u'step',\n",
       " u'stick',\n",
       " u'sticks',\n",
       " u'stir',\n",
       " u'stirring',\n",
       " u'stop',\n",
       " u'store',\n",
       " u'story',\n",
       " u'straight',\n",
       " u'street',\n",
       " u'strong',\n",
       " u'studies',\n",
       " u'study',\n",
       " u'stuff',\n",
       " u'style',\n",
       " u'sugar',\n",
       " u'sugar1',\n",
       " u'summer',\n",
       " u'super',\n",
       " u'support',\n",
       " u'sure',\n",
       " u'surface',\n",
       " u'sweet',\n",
       " u'syrup',\n",
       " u'table',\n",
       " u'tablespoon',\n",
       " u'tablespoons',\n",
       " u'tags',\n",
       " u'taken',\n",
       " u'takes',\n",
       " u'taking',\n",
       " u'talk',\n",
       " u'talking',\n",
       " u'taste',\n",
       " u'tasty',\n",
       " u'tbsp',\n",
       " u'tea',\n",
       " u'team',\n",
       " u'teaspoon',\n",
       " u'teaspoons',\n",
       " u'technology',\n",
       " u'tell',\n",
       " u'temperature',\n",
       " u'tender',\n",
       " u'term',\n",
       " u'test',\n",
       " u'text',\n",
       " u'texture',\n",
       " u'thank',\n",
       " u'thanks',\n",
       " u'thing',\n",
       " u'things',\n",
       " u'think',\n",
       " u'thinking',\n",
       " u'thought',\n",
       " u'throw',\n",
       " u'time',\n",
       " u'times',\n",
       " u'tiny',\n",
       " u'tip',\n",
       " u'tips',\n",
       " u'today',\n",
       " u'told',\n",
       " u'tomato',\n",
       " u'tomatoes',\n",
       " u'took',\n",
       " u'topping',\n",
       " u'toss',\n",
       " u'total',\n",
       " u'totally',\n",
       " u'touch',\n",
       " u'traditional',\n",
       " u'transfer',\n",
       " u'treat',\n",
       " u'tried',\n",
       " u'true',\n",
       " u'truly',\n",
       " u'try',\n",
       " u'trying',\n",
       " u'tsp',\n",
       " u'turn',\n",
       " u'turned',\n",
       " u'turns',\n",
       " u'tv',\n",
       " u'twice',\n",
       " u'twitter',\n",
       " u'type',\n",
       " u'types',\n",
       " u'understand',\n",
       " u'unique',\n",
       " u'united',\n",
       " u'university',\n",
       " u'unsalted',\n",
       " u'unsalted butter',\n",
       " u'use',\n",
       " u'used',\n",
       " u'users',\n",
       " u'uses',\n",
       " u'using',\n",
       " u'usually',\n",
       " u'vanilla',\n",
       " u'vanilla extract',\n",
       " u'variety',\n",
       " u'various',\n",
       " u've',\n",
       " u've got',\n",
       " u'vegetable',\n",
       " u'vegetables',\n",
       " u'version',\n",
       " u'video',\n",
       " u'videos',\n",
       " u'view',\n",
       " u'visit',\n",
       " u'wait',\n",
       " u'want',\n",
       " u'wanted',\n",
       " u'warm',\n",
       " u'wasn',\n",
       " u'watch',\n",
       " u'water',\n",
       " u'way',\n",
       " u'ways',\n",
       " u'wear',\n",
       " u'web',\n",
       " u'website',\n",
       " u'week',\n",
       " u'weekend',\n",
       " u'weeks',\n",
       " u'weight',\n",
       " u'went',\n",
       " u'wet',\n",
       " u'whisk',\n",
       " u'white',\n",
       " u'wide',\n",
       " u'win',\n",
       " u'wine',\n",
       " u'winter',\n",
       " u'wire',\n",
       " u'woman',\n",
       " u'women',\n",
       " u'won',\n",
       " u'wonderful',\n",
       " u'word',\n",
       " u'words',\n",
       " u'work',\n",
       " u'worked',\n",
       " u'working',\n",
       " u'works',\n",
       " u'world',\n",
       " u'worth',\n",
       " u'wouldn',\n",
       " u'wrap',\n",
       " u'write',\n",
       " u'written',\n",
       " u'wrong',\n",
       " u'www',\n",
       " u'year',\n",
       " u'year old',\n",
       " u'years',\n",
       " u'years ago',\n",
       " u'yellow',\n",
       " u'yes',\n",
       " u'york',\n",
       " u'young']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['IBM Sees Holographic Air']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_vectorizer = CountVectorizer(max_features = 1000, ngram_range=(1,2), stop_words='english',binary=True)\n",
    "\n",
    "body_vectorizer = CountVectorizer(max_features = 1000, ngram_range=(1,2), stop_words='english',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=True, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_vectorizer.fit(titles)\n",
    "\n",
    "body_vectorizer.fit(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_X = title_vectorizer.transform(titles)\n",
    "body_X = body_vectorizer.transform(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining steps together in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "title_model = LogisticRegression()\n",
    "title_scores = cross_val_score(title_model, title_X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "body_model = LogisticRegression()\n",
    "body_scores = cross_val_score(body_model, body_X, Y, cv=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging feature sets in pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = data[:6000]\n",
    "title_X_train = training_data['title'].fillna('')\n",
    "Y_train = training_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_X_test = data[6000:]['title'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vec', title_vectorizer),('model', title_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer(analyzer=u'word', binary=True, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "       ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(title_X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46801259,  0.53198741],\n",
       "       [ 0.28316885,  0.71683115],\n",
       "       [ 0.00513415,  0.99486585],\n",
       "       ..., \n",
       "       [ 0.2906378 ,  0.7093622 ],\n",
       "       [ 0.60684131,  0.39315869],\n",
       "       [ 0.66320386,  0.33679614]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict_proba(title_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_scaler = MaxAbsScaler()\n",
    "\n",
    "pipeline = Pipeline([('vec', title_vectorizer),\n",
    "                     ('max_abs_scaler', ma_scaler),\n",
    "                     ('model', title_model)])\n",
    "\n",
    "pipeline.fit(title_X_train, Y_train)\n",
    "\n",
    "pipeline.predict(title_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_pipeline() with preprocessing and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(CountVectorizer(max_features = 1000, ngram_range=(1,2), stop_words='english',binary=True)\n",
    ",MaxAbsScaler(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=True, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='engli...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.fit(title_X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.predict(title_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print pipe1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformer classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureMultiplier(BaseEstimator, transformerMixin):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor \n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        return X * self.factor\n",
    "    \n",
    "    def fit(self,*_):\n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
